{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "\n",
    "def read_data(file):\n",
    "    list_of_titles = set()\n",
    "    with codecs.open(file, \"r\",encoding='utf-8', errors='ignore') as fdata:\n",
    "        spamreader = csv.reader(fdata, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in spamreader:\n",
    "            if line_count == 0:\n",
    "                line_count += 1\n",
    "            else:\n",
    "                title = row[4]\n",
    "                list_of_titles.add(str(title))\n",
    "                line_count += 1\n",
    "        final_doc = list(list_of_titles)\n",
    "        return final_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'CatalogExport.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e4fbfea10297>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0munique_titles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CatalogExport.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-ae45ffe45fca>\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlist_of_titles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mspamreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mline_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py36/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0;31m# Force opening of the file in binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'CatalogExport.csv'"
     ]
    }
   ],
   "source": [
    "unique_titles = read_data('CatalogExport.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "425308"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "snow = SnowballStemmer('english')\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def tokenize(raw_text):\n",
    "    lower_token = [w.lower() for w in word_tokenize(raw_text) if w.isalpha() and w not in stopwords.words('english')]\n",
    "    stem = [snow.stem(w) for w in lower_token]\n",
    "    lemma = [wnl.lemmatize(w) for w in stem]\n",
    "    return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['at', 't', 'worldwid', 'prepaid', 'phone', 'card'],\n",
       " ['pk', 'religi', 'cand', 'milagro', 'de', 'tepeyac'],\n",
       " ['jenna', 'bra', 'yelw', 'dsv', 'onli'],\n",
       " ['davinci', 'jenni', 'lind', 'stationari', 'crib', 'eboni'],\n",
       " ['slice', 'toaster', 'white', 'pk']]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def tokenize(raw_text):\n",
    "    return [w.lower() for w in word_tokenize(raw_text) if w.isalpha() and w not in stopwords.words('english')]'''\n",
    "\n",
    "'''def tokenize(raw_text):\n",
    "    return gensim.utils.simple_preprocess(raw_text)'''\n",
    "\n",
    "def doc_tokenize(document):\n",
    "    result = []\n",
    "    i = 0\n",
    "    while i < len(document):\n",
    "        result.append(tokenize(document[i]))\n",
    "        i += 1\n",
    "    return result\n",
    "\n",
    "doc_tokenize(unique_titles[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = doc_tokenize(unique_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-04 10:05:06,445 : INFO : collecting all words and their counts\n",
      "2018-09-04 10:05:06,446 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-09-04 10:05:06,461 : INFO : PROGRESS: at sentence #10000, processed 46196 words, keeping 9361 word types\n",
      "2018-09-04 10:05:06,477 : INFO : PROGRESS: at sentence #20000, processed 93129 words, keeping 13328 word types\n",
      "2018-09-04 10:05:06,492 : INFO : PROGRESS: at sentence #30000, processed 140151 words, keeping 16253 word types\n",
      "2018-09-04 10:05:06,508 : INFO : PROGRESS: at sentence #40000, processed 186667 words, keeping 18596 word types\n",
      "2018-09-04 10:05:06,526 : INFO : PROGRESS: at sentence #50000, processed 233362 words, keeping 20651 word types\n",
      "2018-09-04 10:05:06,543 : INFO : PROGRESS: at sentence #60000, processed 280011 words, keeping 22517 word types\n",
      "2018-09-04 10:05:06,559 : INFO : PROGRESS: at sentence #70000, processed 326661 words, keeping 24172 word types\n",
      "2018-09-04 10:05:06,577 : INFO : PROGRESS: at sentence #80000, processed 373090 words, keeping 25751 word types\n",
      "2018-09-04 10:05:06,593 : INFO : PROGRESS: at sentence #90000, processed 419763 words, keeping 27144 word types\n",
      "2018-09-04 10:05:06,609 : INFO : PROGRESS: at sentence #100000, processed 466007 words, keeping 28452 word types\n",
      "2018-09-04 10:05:06,627 : INFO : PROGRESS: at sentence #110000, processed 512342 words, keeping 29697 word types\n",
      "2018-09-04 10:05:06,642 : INFO : PROGRESS: at sentence #120000, processed 558883 words, keeping 30835 word types\n",
      "2018-09-04 10:05:06,659 : INFO : PROGRESS: at sentence #130000, processed 605335 words, keeping 31998 word types\n",
      "2018-09-04 10:05:06,676 : INFO : PROGRESS: at sentence #140000, processed 651989 words, keeping 33079 word types\n",
      "2018-09-04 10:05:06,693 : INFO : PROGRESS: at sentence #150000, processed 698595 words, keeping 34135 word types\n",
      "2018-09-04 10:05:06,710 : INFO : PROGRESS: at sentence #160000, processed 745111 words, keeping 35068 word types\n",
      "2018-09-04 10:05:06,724 : INFO : PROGRESS: at sentence #170000, processed 791740 words, keeping 36039 word types\n",
      "2018-09-04 10:05:06,743 : INFO : PROGRESS: at sentence #180000, processed 838314 words, keeping 36960 word types\n",
      "2018-09-04 10:05:06,758 : INFO : PROGRESS: at sentence #190000, processed 884495 words, keeping 37849 word types\n",
      "2018-09-04 10:05:06,776 : INFO : PROGRESS: at sentence #200000, processed 931064 words, keeping 38683 word types\n",
      "2018-09-04 10:05:06,793 : INFO : PROGRESS: at sentence #210000, processed 977500 words, keeping 39513 word types\n",
      "2018-09-04 10:05:06,810 : INFO : PROGRESS: at sentence #220000, processed 1023643 words, keeping 40301 word types\n",
      "2018-09-04 10:05:06,826 : INFO : PROGRESS: at sentence #230000, processed 1070269 words, keeping 41055 word types\n",
      "2018-09-04 10:05:06,844 : INFO : PROGRESS: at sentence #240000, processed 1116417 words, keeping 41815 word types\n",
      "2018-09-04 10:05:06,861 : INFO : PROGRESS: at sentence #250000, processed 1162789 words, keeping 42608 word types\n",
      "2018-09-04 10:05:06,878 : INFO : PROGRESS: at sentence #260000, processed 1209242 words, keeping 43302 word types\n",
      "2018-09-04 10:05:06,895 : INFO : PROGRESS: at sentence #270000, processed 1255623 words, keeping 43943 word types\n",
      "2018-09-04 10:05:06,911 : INFO : PROGRESS: at sentence #280000, processed 1302195 words, keeping 44608 word types\n",
      "2018-09-04 10:05:06,925 : INFO : PROGRESS: at sentence #290000, processed 1348697 words, keeping 45279 word types\n",
      "2018-09-04 10:05:06,942 : INFO : PROGRESS: at sentence #300000, processed 1395428 words, keeping 45962 word types\n",
      "2018-09-04 10:05:06,958 : INFO : PROGRESS: at sentence #310000, processed 1441883 words, keeping 46625 word types\n",
      "2018-09-04 10:05:06,975 : INFO : PROGRESS: at sentence #320000, processed 1488310 words, keeping 47294 word types\n",
      "2018-09-04 10:05:06,990 : INFO : PROGRESS: at sentence #330000, processed 1534416 words, keeping 47935 word types\n",
      "2018-09-04 10:05:07,007 : INFO : PROGRESS: at sentence #340000, processed 1580928 words, keeping 48556 word types\n",
      "2018-09-04 10:05:07,022 : INFO : PROGRESS: at sentence #350000, processed 1627497 words, keeping 49106 word types\n",
      "2018-09-04 10:05:07,038 : INFO : PROGRESS: at sentence #360000, processed 1674009 words, keeping 49726 word types\n",
      "2018-09-04 10:05:07,054 : INFO : PROGRESS: at sentence #370000, processed 1720485 words, keeping 50274 word types\n",
      "2018-09-04 10:05:07,072 : INFO : PROGRESS: at sentence #380000, processed 1766913 words, keeping 50834 word types\n",
      "2018-09-04 10:05:07,088 : INFO : PROGRESS: at sentence #390000, processed 1813363 words, keeping 51386 word types\n",
      "2018-09-04 10:05:07,105 : INFO : PROGRESS: at sentence #400000, processed 1859966 words, keeping 51942 word types\n",
      "2018-09-04 10:05:07,121 : INFO : PROGRESS: at sentence #410000, processed 1906318 words, keeping 52500 word types\n",
      "2018-09-04 10:05:07,138 : INFO : PROGRESS: at sentence #420000, processed 1952699 words, keeping 52963 word types\n",
      "2018-09-04 10:05:07,148 : INFO : collected 53238 word types from a corpus of 1977455 raw words and 425308 sentences\n",
      "2018-09-04 10:05:07,148 : INFO : Loading a fresh vocabulary\n",
      "2018-09-04 10:05:07,204 : INFO : min_count=3 retains 24223 unique words (45% of original 53238, drops 29015)\n",
      "2018-09-04 10:05:07,204 : INFO : min_count=3 leaves 1941343 word corpus (98% of original 1977455, drops 36112)\n",
      "2018-09-04 10:05:07,272 : INFO : deleting the raw counts dictionary of 53238 items\n",
      "2018-09-04 10:05:07,274 : INFO : sample=0.001 downsamples 27 most-common words\n",
      "2018-09-04 10:05:07,275 : INFO : downsampling leaves estimated 1849447 word corpus (95.3% of prior 1941343)\n",
      "2018-09-04 10:05:07,343 : INFO : estimated required memory for 24223 words and 100 dimensions: 31489900 bytes\n",
      "2018-09-04 10:05:07,344 : INFO : resetting layer weights\n",
      "2018-09-04 10:05:07,617 : INFO : training model with 6 workers on 24223 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-09-04 10:05:08,641 : INFO : EPOCH 1 - PROGRESS: at 62.18% examples, 1138396 words/s, in_qsize 9, out_qsize 2\n",
      "2018-09-04 10:05:09,155 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:09,169 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:09,171 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:09,172 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:09,178 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:09,181 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:09,182 : INFO : EPOCH - 1 : training on 1977455 raw words (1849866 effective words) took 1.6s, 1192396 effective words/s\n",
      "2018-09-04 10:05:10,197 : INFO : EPOCH 2 - PROGRESS: at 57.62% examples, 1058341 words/s, in_qsize 12, out_qsize 0\n",
      "2018-09-04 10:05:10,804 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:10,812 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:10,813 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:10,822 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:10,823 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:10,825 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:10,825 : INFO : EPOCH - 2 : training on 1977455 raw words (1849702 effective words) took 1.6s, 1131039 effective words/s\n",
      "2018-09-04 10:05:11,838 : INFO : EPOCH 3 - PROGRESS: at 61.66% examples, 1135263 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-04 10:05:12,391 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:12,394 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:12,408 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:12,410 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:12,412 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:12,413 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:12,413 : INFO : EPOCH - 3 : training on 1977455 raw words (1849776 effective words) took 1.6s, 1170341 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-04 10:05:13,431 : INFO : EPOCH 4 - PROGRESS: at 60.15% examples, 1106703 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-04 10:05:13,985 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:13,992 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:13,993 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:14,001 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:14,003 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:14,004 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:14,005 : INFO : EPOCH - 4 : training on 1977455 raw words (1849235 effective words) took 1.6s, 1170706 effective words/s\n",
      "2018-09-04 10:05:15,029 : INFO : EPOCH 5 - PROGRESS: at 62.17% examples, 1137262 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-04 10:05:15,548 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:15,554 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:15,554 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:15,557 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:15,565 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:15,567 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:15,567 : INFO : EPOCH - 5 : training on 1977455 raw words (1849564 effective words) took 1.5s, 1193460 effective words/s\n",
      "2018-09-04 10:05:15,568 : INFO : training on a 9887275 raw words (9248143 effective words) took 7.9s, 1163308 effective words/s\n",
      "2018-09-04 10:05:15,576 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-09-04 10:05:15,576 : INFO : training model with 6 workers on 24223 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-09-04 10:05:16,585 : INFO : EPOCH 1 - PROGRESS: at 61.16% examples, 1130341 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-04 10:05:17,115 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:17,129 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:17,134 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:17,136 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:17,146 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:17,147 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:17,148 : INFO : EPOCH - 1 : training on 1977455 raw words (1849219 effective words) took 1.6s, 1182935 effective words/s\n",
      "2018-09-04 10:05:18,160 : INFO : EPOCH 2 - PROGRESS: at 62.68% examples, 1155039 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-04 10:05:18,777 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:18,787 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:18,791 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:18,792 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:18,800 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:18,803 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:18,804 : INFO : EPOCH - 2 : training on 1977455 raw words (1849196 effective words) took 1.6s, 1122070 effective words/s\n",
      "2018-09-04 10:05:19,813 : INFO : EPOCH 3 - PROGRESS: at 56.09% examples, 1038069 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-04 10:05:20,536 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:20,546 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:20,547 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:20,551 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:20,556 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:20,558 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:20,558 : INFO : EPOCH - 3 : training on 1977455 raw words (1849852 effective words) took 1.7s, 1059742 effective words/s\n",
      "2018-09-04 10:05:21,577 : INFO : EPOCH 4 - PROGRESS: at 56.59% examples, 1036884 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-04 10:05:22,182 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:22,184 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:22,185 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:22,186 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:22,195 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:22,200 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:22,201 : INFO : EPOCH - 4 : training on 1977455 raw words (1849160 effective words) took 1.6s, 1131250 effective words/s\n",
      "2018-09-04 10:05:23,220 : INFO : EPOCH 5 - PROGRESS: at 64.20% examples, 1175099 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-04 10:05:23,682 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:23,699 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:23,701 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:23,701 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:23,702 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:23,702 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:23,703 : INFO : EPOCH - 5 : training on 1977455 raw words (1849692 effective words) took 1.5s, 1238163 effective words/s\n",
      "2018-09-04 10:05:24,731 : INFO : EPOCH 6 - PROGRESS: at 63.69% examples, 1159029 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-04 10:05:25,198 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:25,204 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:25,206 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:25,208 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:25,210 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:25,219 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:25,220 : INFO : EPOCH - 6 : training on 1977455 raw words (1849550 effective words) took 1.5s, 1228674 effective words/s\n",
      "2018-09-04 10:05:26,245 : INFO : EPOCH 7 - PROGRESS: at 62.67% examples, 1144222 words/s, in_qsize 9, out_qsize 2\n",
      "2018-09-04 10:05:26,758 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:26,765 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:26,766 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:26,769 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:26,774 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:26,780 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:26,781 : INFO : EPOCH - 7 : training on 1977455 raw words (1849642 effective words) took 1.5s, 1193825 effective words/s\n",
      "2018-09-04 10:05:27,791 : INFO : EPOCH 8 - PROGRESS: at 63.69% examples, 1176575 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-04 10:05:28,334 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:28,338 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:28,344 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:28,351 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:28,354 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:28,356 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-04 10:05:28,356 : INFO : EPOCH - 8 : training on 1977455 raw words (1849584 effective words) took 1.6s, 1180510 effective words/s\n",
      "2018-09-04 10:05:29,398 : INFO : EPOCH 9 - PROGRESS: at 63.69% examples, 1145157 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-04 10:05:29,875 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:29,881 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:29,882 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:29,890 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:29,892 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:29,894 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:29,894 : INFO : EPOCH - 9 : training on 1977455 raw words (1849520 effective words) took 1.5s, 1212914 effective words/s\n",
      "2018-09-04 10:05:30,909 : INFO : EPOCH 10 - PROGRESS: at 61.16% examples, 1128693 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-04 10:05:31,441 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:31,451 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:31,452 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:31,456 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:31,464 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:31,466 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:31,466 : INFO : EPOCH - 10 : training on 1977455 raw words (1849259 effective words) took 1.6s, 1185846 effective words/s\n",
      "2018-09-04 10:05:32,491 : INFO : EPOCH 11 - PROGRESS: at 62.17% examples, 1144571 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-04 10:05:33,019 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:33,021 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:33,026 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:33,028 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:33,034 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:33,037 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:33,038 : INFO : EPOCH - 11 : training on 1977455 raw words (1849711 effective words) took 1.6s, 1191639 effective words/s\n",
      "2018-09-04 10:05:34,063 : INFO : EPOCH 12 - PROGRESS: at 62.17% examples, 1136185 words/s, in_qsize 11, out_qsize 1\n",
      "2018-09-04 10:05:34,613 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:34,626 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:34,631 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:34,632 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:34,645 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:34,647 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:34,647 : INFO : EPOCH - 12 : training on 1977455 raw words (1849236 effective words) took 1.6s, 1158013 effective words/s\n",
      "2018-09-04 10:05:35,672 : INFO : EPOCH 13 - PROGRESS: at 63.19% examples, 1151238 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-04 10:05:36,183 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:36,189 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:36,203 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:36,204 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:36,211 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:36,213 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:36,213 : INFO : EPOCH - 13 : training on 1977455 raw words (1849341 effective words) took 1.6s, 1187599 effective words/s\n",
      "2018-09-04 10:05:37,235 : INFO : EPOCH 14 - PROGRESS: at 61.17% examples, 1119924 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-04 10:05:37,765 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:37,767 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:37,775 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:37,781 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:37,783 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:37,784 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:37,784 : INFO : EPOCH - 14 : training on 1977455 raw words (1849134 effective words) took 1.6s, 1186016 effective words/s\n",
      "2018-09-04 10:05:38,799 : INFO : EPOCH 15 - PROGRESS: at 62.17% examples, 1148275 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-04 10:05:39,330 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:39,338 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:39,344 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:39,345 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:39,352 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:39,355 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:39,355 : INFO : EPOCH - 15 : training on 1977455 raw words (1849295 effective words) took 1.6s, 1186868 effective words/s\n",
      "2018-09-04 10:05:40,371 : INFO : EPOCH 16 - PROGRESS: at 63.18% examples, 1160039 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-04 10:05:40,851 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:40,857 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:40,858 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:40,867 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:40,868 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:40,869 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:40,869 : INFO : EPOCH - 16 : training on 1977455 raw words (1849253 effective words) took 1.5s, 1228153 effective words/s\n",
      "2018-09-04 10:05:41,882 : INFO : EPOCH 17 - PROGRESS: at 64.69% examples, 1191757 words/s, in_qsize 9, out_qsize 2\n",
      "2018-09-04 10:05:42,357 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:42,360 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:42,372 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:42,375 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:42,376 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:42,377 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:42,378 : INFO : EPOCH - 17 : training on 1977455 raw words (1849519 effective words) took 1.5s, 1232985 effective words/s\n",
      "2018-09-04 10:05:43,395 : INFO : EPOCH 18 - PROGRESS: at 63.69% examples, 1168651 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-04 10:05:43,861 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:43,870 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:43,872 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:43,875 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:43,881 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:43,886 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:43,886 : INFO : EPOCH - 18 : training on 1977455 raw words (1849514 effective words) took 1.5s, 1233235 effective words/s\n",
      "2018-09-04 10:05:44,910 : INFO : EPOCH 19 - PROGRESS: at 65.20% examples, 1192405 words/s, in_qsize 11, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-04 10:05:45,370 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:45,388 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:45,390 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:45,391 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:45,400 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:45,402 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:45,403 : INFO : EPOCH - 19 : training on 1977455 raw words (1849182 effective words) took 1.5s, 1228630 effective words/s\n",
      "2018-09-04 10:05:46,414 : INFO : EPOCH 20 - PROGRESS: at 63.69% examples, 1177974 words/s, in_qsize 9, out_qsize 2\n",
      "2018-09-04 10:05:46,900 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:46,907 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:46,908 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:46,912 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:46,920 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:46,922 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:46,922 : INFO : EPOCH - 20 : training on 1977455 raw words (1849511 effective words) took 1.5s, 1226037 effective words/s\n",
      "2018-09-04 10:05:47,953 : INFO : EPOCH 21 - PROGRESS: at 63.68% examples, 1155374 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-04 10:05:48,436 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:48,452 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:48,455 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:48,456 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:48,457 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:48,459 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:48,459 : INFO : EPOCH - 21 : training on 1977455 raw words (1849647 effective words) took 1.5s, 1211823 effective words/s\n",
      "2018-09-04 10:05:49,480 : INFO : EPOCH 22 - PROGRESS: at 64.19% examples, 1184984 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-04 10:05:49,958 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:49,960 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:49,961 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:49,974 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:49,974 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:49,975 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:49,976 : INFO : EPOCH - 22 : training on 1977455 raw words (1849644 effective words) took 1.5s, 1234200 effective words/s\n",
      "2018-09-04 10:05:50,986 : INFO : EPOCH 23 - PROGRESS: at 61.16% examples, 1130306 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-04 10:05:51,592 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:51,595 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:51,598 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:51,600 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:51,609 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:51,611 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:51,611 : INFO : EPOCH - 23 : training on 1977455 raw words (1849380 effective words) took 1.6s, 1136983 effective words/s\n",
      "2018-09-04 10:05:52,633 : INFO : EPOCH 24 - PROGRESS: at 63.69% examples, 1172421 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-04 10:05:53,117 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:53,131 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:53,132 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:53,134 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:53,139 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:53,142 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:53,143 : INFO : EPOCH - 24 : training on 1977455 raw words (1849258 effective words) took 1.5s, 1221151 effective words/s\n",
      "2018-09-04 10:05:54,173 : INFO : EPOCH 25 - PROGRESS: at 64.70% examples, 1175552 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-04 10:05:54,641 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:54,651 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:54,651 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:54,656 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:54,661 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:54,666 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:54,667 : INFO : EPOCH - 25 : training on 1977455 raw words (1849478 effective words) took 1.5s, 1223102 effective words/s\n",
      "2018-09-04 10:05:55,692 : INFO : EPOCH 26 - PROGRESS: at 63.19% examples, 1154319 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-04 10:05:56,191 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:56,192 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:56,192 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:56,194 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:56,201 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:56,204 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:56,204 : INFO : EPOCH - 26 : training on 1977455 raw words (1849218 effective words) took 1.5s, 1213160 effective words/s\n",
      "2018-09-04 10:05:57,228 : INFO : EPOCH 27 - PROGRESS: at 64.20% examples, 1184553 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-04 10:05:57,701 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:57,707 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:57,708 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:57,717 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:57,719 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:57,720 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:57,720 : INFO : EPOCH - 27 : training on 1977455 raw words (1849379 effective words) took 1.5s, 1236929 effective words/s\n",
      "2018-09-04 10:05:58,742 : INFO : EPOCH 28 - PROGRESS: at 64.70% examples, 1194214 words/s, in_qsize 12, out_qsize 0\n",
      "2018-09-04 10:05:59,223 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:05:59,229 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:05:59,231 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:05:59,232 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:05:59,239 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:05:59,241 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:05:59,242 : INFO : EPOCH - 28 : training on 1977455 raw words (1849258 effective words) took 1.5s, 1231307 effective words/s\n",
      "2018-09-04 10:06:00,256 : INFO : EPOCH 29 - PROGRESS: at 62.17% examples, 1142373 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-04 10:06:00,772 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:06:00,775 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:06:00,776 : INFO : worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-04 10:06:00,787 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:06:00,789 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:06:00,789 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:06:00,789 : INFO : EPOCH - 29 : training on 1977455 raw words (1849605 effective words) took 1.5s, 1200732 effective words/s\n",
      "2018-09-04 10:06:01,805 : INFO : EPOCH 30 - PROGRESS: at 63.69% examples, 1176888 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-04 10:06:02,302 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 10:06:02,309 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 10:06:02,310 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 10:06:02,320 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 10:06:02,320 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 10:06:02,322 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 10:06:02,323 : INFO : EPOCH - 30 : training on 1977455 raw words (1849709 effective words) took 1.5s, 1217328 effective words/s\n",
      "2018-09-04 10:06:02,324 : INFO : training on a 59323650 raw words (55482946 effective words) took 46.7s, 1186837 effective words/s\n",
      "2018-09-04 10:06:02,324 : INFO : saving Word2Vec object under word2vec.model, separately None\n",
      "2018-09-04 10:06:02,325 : INFO : not storing attribute vectors_norm\n",
      "2018-09-04 10:06:02,326 : INFO : not storing attribute cum_table\n",
      "2018-09-04 10:06:02,589 : INFO : saved word2vec.model\n"
     ]
    }
   ],
   "source": [
    "import gensim \n",
    "import logging\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "model = gensim.models.Word2Vec(\n",
    "        result,\n",
    "        size=100,\n",
    "        window=5,\n",
    "        min_count=3,\n",
    "        workers=6)\n",
    "\n",
    "model.train(result, total_examples=len(result), epochs=30)\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-04 10:24:22,926 : INFO : loading Word2Vec object from word2vec.model\n",
      "2018-09-04 10:24:23,112 : INFO : loading wv recursively from word2vec.model.wv.* with mmap=None\n",
      "2018-09-04 10:24:23,113 : INFO : setting ignored attribute vectors_norm to None\n",
      "2018-09-04 10:24:23,114 : INFO : loading vocabulary recursively from word2vec.model.vocabulary.* with mmap=None\n",
      "2018-09-04 10:24:23,114 : INFO : loading trainables recursively from word2vec.model.trainables.* with mmap=None\n",
      "2018-09-04 10:24:23,115 : INFO : setting ignored attribute cum_table to None\n",
      "2018-09-04 10:24:23,115 : INFO : loaded word2vec.model\n",
      "2018-09-04 10:24:23,165 : INFO : saving Word2VecKeyedVectors object under custom_w2v.wv, separately None\n",
      "2018-09-04 10:24:23,166 : INFO : not storing attribute vectors_norm\n",
      "2018-09-04 10:24:23,296 : INFO : saved custom_w2v.wv\n",
      "2018-09-04 10:24:23,297 : INFO : loading Word2VecKeyedVectors object from custom_w2v.wv\n",
      "2018-09-04 10:24:23,675 : INFO : setting ignored attribute vectors_norm to None\n",
      "2018-09-04 10:24:23,676 : INFO : loaded custom_w2v.wv\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec.load(\"word2vec.model\")\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "#path = get_tmpfile(\"wordvectors.kv\")\n",
    "model.wv.save(\"custom_w2v.wv\")\n",
    "wv = KeyedVectors.load(\"custom_w2v.wv\", mmap='r')\n",
    "vector = wv['computer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.6541559e-04,  5.4638743e-01, -4.8581070e-01, -1.7046310e-01,\n",
       "        3.9842412e-01, -4.7212309e-01, -5.5947043e-02, -8.2077414e-01,\n",
       "        9.4980672e-03, -1.3582918e-01,  4.2045781e-01,  3.8501278e-01,\n",
       "        1.3958721e-01, -5.7157052e-01,  1.1066034e-01,  1.0075362e-01,\n",
       "        2.1408598e-01,  9.3061090e-02, -1.9670087e-01, -3.3826120e-02,\n",
       "        2.1080868e-01,  4.8353678e-01, -1.3563891e-01, -1.6375139e-01,\n",
       "       -3.4307498e-01,  1.3208222e-01,  5.4267541e-02, -1.6608623e-01,\n",
       "       -4.7752434e-01, -2.9516700e-01, -1.8619831e-01,  2.9539065e-03,\n",
       "        2.6558158e-01,  1.7765800e-02, -3.1637922e-01, -2.4835896e-02,\n",
       "       -1.0231326e-02,  4.8382513e-02,  4.2598569e-01, -4.4409037e-02,\n",
       "       -2.6690286e-01,  2.3039199e-01,  1.0563161e-01, -2.5389719e-01,\n",
       "        1.5625264e-02, -1.6247703e-01, -1.3944232e-01, -4.0982795e-01,\n",
       "       -4.0991116e-02, -2.5796080e-01,  1.4209364e-01,  3.1002471e-01,\n",
       "        5.0410146e-01,  4.7874516e-01, -1.8515545e-01, -3.7745245e-02,\n",
       "       -1.9633906e-01,  1.6593814e-01, -2.0382194e-01, -1.2516469e-01,\n",
       "        5.2954014e-02,  4.9521092e-01,  1.0144653e+00,  4.8910283e-02,\n",
       "        6.9843188e-02,  4.9859840e-02, -4.4914730e-02, -5.4145604e-01,\n",
       "        8.7368049e-02, -1.9078484e-02, -4.7730349e-02, -1.3927215e-01,\n",
       "       -5.6585453e-02, -5.7410711e-01,  2.3708223e-01,  2.2422907e-01,\n",
       "       -6.8384749e-01, -3.2244042e-01,  3.4661844e-02, -2.5821042e-01,\n",
       "        1.3164942e-01, -1.5556896e-01,  2.1031801e-01, -1.4549790e-01,\n",
       "       -1.8819658e-01,  1.3789709e-01, -2.4762417e-01,  6.9136009e-02,\n",
       "       -1.7713070e-01, -1.0796150e-01,  5.6493723e-01, -8.5271969e-02,\n",
       "        2.3107752e-02, -4.9995225e-02,  4.9386483e-01, -7.9599380e-01,\n",
       "        1.6429539e-01,  3.6716843e-01,  4.2877127e-03, -3.3821318e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nexstar', 0.7160414457321167),\n",
       " ('sew', 0.6995350122451782),\n",
       " ('astromast', 0.6899140477180481),\n",
       " ('intellifax', 0.6632629632949829),\n",
       " ('dsmobil', 0.643893837928772),\n",
       " ('celestron', 0.6172360181808472),\n",
       " ('multilingu', 0.6168195009231567),\n",
       " ('frei', 0.6002721786499023),\n",
       " ('berr', 0.5924490690231323),\n",
       " ('imagecent', 0.553000807762146)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get everything related to stuff on the bed# get ev \n",
    "w1 = [\"computer\"]\n",
    "wv.most_similar (positive=w1,topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-04 10:23:14,220 : INFO : loading projection weights from /Users/n0s00a6/gensim-data/glove-wiki-gigaword-100/glove-wiki-gigaword-100.gz\n",
      "2018-09-04 10:23:51,408 : INFO : loaded (400000, 100) matrix from /Users/n0s00a6/gensim-data/glove-wiki-gigaword-100/glove-wiki-gigaword-100.gz\n",
      "2018-09-04 10:23:51,469 : INFO : saving Word2VecKeyedVectors object under glove.wv, separately None\n",
      "2018-09-04 10:23:51,470 : INFO : storing np array 'vectors' to glove.wv.vectors.npy\n",
      "2018-09-04 10:23:51,664 : INFO : not storing attribute vectors_norm\n",
      "2018-09-04 10:23:52,567 : INFO : saved glove.wv\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "word_vectors = api.load(\"glove-wiki-gigaword-100\")\n",
    "\n",
    "word_vectors.save(\"glove.wv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-04 10:22:09,906 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('laptops', 0.8518658876419067),\n",
       " ('computers', 0.7559926509857178),\n",
       " ('phones', 0.7229112982749939),\n",
       " ('portable', 0.7157840728759766),\n",
       " ('desktop', 0.7085691690444946),\n",
       " ('ipod', 0.704980731010437),\n",
       " ('computer', 0.7024158239364624),\n",
       " ('handheld', 0.6808915138244629),\n",
       " ('pc', 0.67621910572052),\n",
       " ('cellphones', 0.6729860901832581)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = [\"laptop\"]\n",
    "word_vectors.most_similar (positive=w1,topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
