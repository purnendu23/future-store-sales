{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goal :: Predict the sale (number of items) for the shop-item pair in the  test set. The test set is for one month - November 2015 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, date\n",
    "from calendar import monthrange\n",
    "from pytz import timezone\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import feather\n",
    "import datetime \n",
    "import pytz\n",
    "import csv\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "def get_dates_in_month(year, month, time_zone):\n",
    "    num_days = monthrange(year, month)[1]\n",
    "    first_date_of_month = datetime.datetime(year,month,1, tzinfo=time_zone)\n",
    "    last_date_of_month =  datetime.datetime(year,month,num_days, tzinfo=time_zone)\n",
    "    return get_dates_inrange(first_date_of_month, last_date_of_month)\n",
    "\n",
    "def get_dates_inrange(date1, date2):\n",
    "    if (not isinstance(date1, datetime.datetime)) | (not isinstance(date2, datetime.datetime)):\n",
    "        return \"date1 and date2 should be of type datetime.date\"\n",
    "    num_days = (date2 - date1).days + 1\n",
    "    date_list = [date1 + datetime.timedelta(days=x) for x in range(0, num_days)]\n",
    "    return date_list\n",
    "\n",
    "def remove_nonAlphaNumeric(s: str):\n",
    "    return re.sub(r'\\W+', '', s)\n",
    "\n",
    "def tokenize(raw_text: str):\n",
    "    lower_tokens = [w.lower() for w in word_tokenize(raw_text)]\n",
    "    refined_tokens = [remove_nonAlphaNumeric(w) for w in lower_tokens]\n",
    "    return list(filter(None, refined_tokens))\n",
    "\n",
    "def w2v_vectorize(raw_text: str, model):\n",
    "    words = tokenize(raw_text)\n",
    "    word_vectors = model.wv\n",
    "    vector = [0] * model.wv.vector_size\n",
    "    for word in words:\n",
    "        if word in word_vectors.vocab:\n",
    "            vector += word_vectors.get_vector(word)\n",
    "    vector = [np.round(d, 4) for d in vector]\n",
    "    return vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = './data/'\n",
    "ADD_RESOURCES = './res/'\n",
    "\n",
    "sales    = pd.read_csv(os.path.join(DATA_FOLDER, 'sales_train.csv.gz'))\n",
    "items           = pd.read_csv(os.path.join(DATA_FOLDER, 'items.csv'))\n",
    "item_categories = pd.read_csv(os.path.join(DATA_FOLDER, 'item_categories.csv'))\n",
    "shops           = pd.read_csv(os.path.join(DATA_FOLDER, 'shops.csv'))\n",
    "test = pd.read_csv(os.path.join(DATA_FOLDER, 'test.csv.gz')) \n",
    "\n",
    "date_df = pd.read_pickle(os.path.join(ADD_RESOURCES, \"russian_holidays.pkl\"))\n",
    "geography = pd.read_csv(os.path.join(ADD_RESOURCES, 'geography.csv'))\n",
    "holidays = feather.read_dataframe(os.path.join(ADD_RESOURCES, 'hol.feather'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data (sales) -> (2935849, 6)\n",
      "test data -> (214200, 3)\n",
      "\n",
      "\n",
      "Total Items: 22170\n",
      "Total Categories: 84\n",
      "Total Shops: 60\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "Training data\n",
      "  # unique shops: 60\n",
      "  # unique items: 21807\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "Test data\n",
      "  # unique shops: 42\n",
      "  # unique items: 5100\n",
      "\n",
      "\n",
      "\n",
      "# items in test set: 5100\n",
      "# items in test set and transaction set: 4737\n",
      "# items in test but not transaction: 363\n",
      "\n",
      "\n",
      "# shops in test set: 42\n",
      "# shops in test set and transaction set: 42\n",
      "# shops in test but not transaction: 0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  shop_id  item_id\n",
       "0   0        5     5037\n",
       "1   1        5     5320\n",
       "2   2        5     5233\n",
       "3   3        5     5232\n",
       "4   4        5     5268"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"training data (sales) -> \" + str(sales.shape))\n",
    "print(\"test data -> \" + str(test.shape))\n",
    "print(\"\\n\")\n",
    "print(\"Total Items: {}\".format(items.item_id.nunique()))\n",
    "print(\"Total Categories: {}\".format(item_categories.item_category_id.nunique()))\n",
    "print(\"Total Shops: {}\".format(shops.shop_id.nunique()))\n",
    "print(\"\\n--------------------------------------------------------\\n\")\n",
    "\n",
    "print(\"Training data\")\n",
    "print(\"  # unique shops: {}\".format(sales.shop_id.nunique()))\n",
    "print(\"  # unique items: {}\".format(sales.item_id.nunique()))\n",
    "\n",
    "print(\"\\n--------------------------------------------------------\\n\")\n",
    "print(\"Test data\")\n",
    "print(\"  # unique shops: {}\".format(test.shop_id.nunique()))\n",
    "print(\"  # unique items: {}\".format(test.item_id.nunique()))\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "transactions = sales\n",
    "# Drop the rows with price lt zero. ther is only one.\n",
    "transactions = transactions[transactions.item_price > 0]\n",
    "\n",
    "# Merging to get category_id in the transaction df\n",
    "transactions = pd.merge(transactions, items[['item_id', 'item_category_id']], on='item_id', how='left')\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "items_test_nottrans = len(set(test.item_id.unique()) - set(test.item_id.unique()).intersection(set(transactions.item_id.unique())))\n",
    "intersection_items_test_transac = len(set(test.item_id.unique()).intersection(set(transactions.item_id.unique())))\n",
    "item_count_test = len(set(test.item_id.unique()))\n",
    "\n",
    "print(\"# items in test set: {}\".format(item_count_test))\n",
    "print(\"# items in test set and transaction set: {}\".format(intersection_items_test_transac))\n",
    "print(\"# items in test but not transaction: {}\".format(items_test_nottrans))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "shops_test_nottrans = len(set(test.shop_id.unique()) - set(test.shop_id.unique()).intersection(set(transactions.shop_id.unique())))\n",
    "intersection_shops_test_transac = len(set(test.shop_id.unique()).intersection(set(transactions.shop_id.unique())))\n",
    "shop_count_test = len(set(test.shop_id.unique()))\n",
    "\n",
    "print(\"# shops in test set: {}\".format(shop_count_test))\n",
    "print(\"# shops in test set and transaction set: {}\".format(intersection_shops_test_transac))\n",
    "print(\"# shops in test but not transaction: {}\".format(shops_test_nottrans))\n",
    "\n",
    "print(\"\\n\")\n",
    " \n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(test.item_id.unique()))\n",
    "\n",
    "len( set(test.item_id.unique()).intersection(set(items.item_id.unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building the shops data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_name</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>shop_type</th>\n",
       "      <th>city</th>\n",
       "      <th>time_wrt_utc</th>\n",
       "      <th>fed_subject</th>\n",
       "      <th>fed_dist</th>\n",
       "      <th>dist_from_moscow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!Якутск Орджоникидзе, 56 фран</td>\n",
       "      <td>0</td>\n",
       "      <td>OTH</td>\n",
       "      <td>Якутск</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Sakha Republic</td>\n",
       "      <td>Far East</td>\n",
       "      <td>8395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!Якутск ТЦ \"Центральный\" фран</td>\n",
       "      <td>1</td>\n",
       "      <td>ТЦ</td>\n",
       "      <td>Якутск</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Sakha Republic</td>\n",
       "      <td>Far East</td>\n",
       "      <td>8395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Адыгея ТЦ \"Мега\"</td>\n",
       "      <td>2</td>\n",
       "      <td>ТЦ</td>\n",
       "      <td>Адыгея</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Adygea Republic</td>\n",
       "      <td>South</td>\n",
       "      <td>1589.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Балашиха ТРК \"Октябрь-Киномир\"</td>\n",
       "      <td>3</td>\n",
       "      <td>ТРК</td>\n",
       "      <td>Балашиха</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Moscow Oblast</td>\n",
       "      <td>Central</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Волжский ТЦ \"Волга Молл\"</td>\n",
       "      <td>4</td>\n",
       "      <td>ТЦ</td>\n",
       "      <td>Волжский</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Volgograd Oblast</td>\n",
       "      <td>South</td>\n",
       "      <td>993.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        shop_name  shop_id shop_type      city  time_wrt_utc  \\\n",
       "0   !Якутск Орджоникидзе, 56 фран        0       OTH    Якутск           9.0   \n",
       "1   !Якутск ТЦ \"Центральный\" фран        1        ТЦ    Якутск           9.0   \n",
       "2                Адыгея ТЦ \"Мега\"        2        ТЦ    Адыгея           3.0   \n",
       "3  Балашиха ТРК \"Октябрь-Киномир\"        3       ТРК  Балашиха           3.0   \n",
       "4        Волжский ТЦ \"Волга Молл\"        4        ТЦ  Волжский           3.0   \n",
       "\n",
       "        fed_subject  fed_dist  dist_from_moscow  \n",
       "0    Sakha Republic  Far East            8395.0  \n",
       "1    Sakha Republic  Far East            8395.0  \n",
       "2   Adygea Republic     South            1589.0  \n",
       "3     Moscow Oblast   Central              26.0  \n",
       "4  Volgograd Oblast     South             993.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the shop_type\n",
    "shops_df = shops\n",
    "\n",
    "shop_types = ['ТЦ', 'ТРК', 'ТРЦ', 'МТРЦ', 'ТК', 'online']\n",
    "shops_df[\"shop_type\"] = shops_df.shop_name.apply(lambda x: x.split()[1] if x.split()[1] in shop_types else 'OTH')\n",
    "shops_df.loc[shops_df.shop_id.isin([12, 55]) , 'shop_type'] = \"online\"\n",
    "shops_df.loc[shops_df.shop_id == 9 , 'shop_type'] = \"outbound\"\n",
    "\n",
    "# Setting the city for each shop\n",
    "shops_df[\"city\"] = shops_df.shop_name.apply(lambda x: x.split()[0].replace(\"!\", \"\"))\n",
    "shops_df.loc[shops_df.city.isin([\"Интернет-магазин\", \"Цифровой\", \"Выездная\"]) , 'city'] = \"no_city\"\n",
    "\n",
    " # Appending the geographic info to shops df\n",
    "shops_df = pd.merge(shops_df, geography.drop(['city_eng'], axis=1), on='city', how='left')\n",
    "\n",
    "\n",
    "# Get rid of NaN values from 'time_wrt_utc' and 'dist_from_moscow' columns\n",
    "# for c in ['time_wrt_utc', 'dist_from_moscow']:\n",
    "#     shops_df.loc[shops_df[c].isnull(), c] = np.mean(shops_df[c])\n",
    "\n",
    "# Changing the type to 'category'\n",
    "catg = ['shop_type', 'city', 'fed_subject', 'fed_dist']\n",
    "for c in catg:\n",
    "    shops_df[c] = shops_df[c].astype('category')\n",
    "\n",
    "print(shops_df.shape)\n",
    "shops_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are entries for Online - 'shops'\n",
    "\n",
    "Выездная Торговля\t9\tOTH\tВыездная\t-1\tNaN\tNaN\t-1          (exit trade)\n",
    "\n",
    "Интернет-магазин ЧС\t12\tOTH\tИнтернет-магазин\t-1\tNaN\tNaN\t-1   (Online shop Emergency)\n",
    "\n",
    "Цифровой склад 1С-Онлайн\t55\tOTH\tЦифровой\t-1\tNaN\tNaN\t-1 (Digital warehouse 1C-Online)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a date df, and block_num_info df for adding temporal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>weekends</th>\n",
       "      <th>holidays</th>\n",
       "      <th>off_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  weekends  holidays  off_days\n",
       "0               0       8.0       7.0        14\n",
       "1               1       8.0       2.0         8\n",
       "2               2      10.0       2.0        11\n",
       "3               3       8.0       0.0         8\n",
       "4               4       8.0       9.0        16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up the calendar and the Block_num info dataframe\n",
    "\n",
    "moscow = timezone('Europe/Moscow')\n",
    "train_first_date = datetime.datetime(2013,1,1, tzinfo=moscow)\n",
    "train_last_date =  datetime.datetime(2015,11,30, tzinfo=moscow)\n",
    "\n",
    "date_df = pd.DataFrame(get_dates_inrange(train_first_date, train_last_date), columns=['date'])\n",
    "\n",
    "date_df['weekday'] = date_df['date'].apply(lambda x: x.isoweekday())\n",
    "date_df['is_weekend'] = date_df['weekday'] > 5\n",
    "\n",
    "# Holidays dataframe - (preparing df)\n",
    "holidays_b = holidays\n",
    "holidays_b['date_str'] = holidays_b.date.apply(lambda x: x.isoformat().split(\"T\")[0])\n",
    "holidays_b['off_day'] =  holidays_b.h_type.apply(lambda x: x.split(\",\")[0] == 'National holiday')\n",
    "holidays_b['is_holiday'] = True\n",
    "\n",
    "date_df['date_str'] = date_df.date.apply(lambda x: x.isoformat().split(\"T\")[0])\n",
    "\n",
    "date_df = pd.merge(date_df, holidays_b[['date_str', 'is_holiday']], on='date_str', how='left')\n",
    "date_df['is_holiday'].fillna(False, inplace=True)\n",
    "\n",
    "date_df = pd.merge(date_df, holidays_b[['off_day', 'date_str']], on='date_str', how='left')\n",
    "date_df.loc[date_df.loc[:, 'weekday'] > 5, 'off_day'] = True\n",
    "\n",
    "\n",
    "def add_date_block_num(d):\n",
    "    if(d.year == 2013):\n",
    "        base=0\n",
    "    elif(d.year == 2014):\n",
    "        base=12\n",
    "    elif(d.year == 2015): \n",
    "        base=24\n",
    "    return base + (d.month-1)\n",
    "\n",
    "date_df['date_block_num'] = date_df['date'].apply(lambda x: add_date_block_num(x))\n",
    "\n",
    "date_df.head()\n",
    "\n",
    "\n",
    "# Block info df\n",
    "block_num_info = date_df[date_df.is_weekend == True].groupby('date_block_num')['is_weekend'].sum().reset_index(name = \"weekends\")\n",
    "\n",
    "block_num_info['holidays'] = date_df[date_df.is_holiday == True].groupby('date_block_num')['is_holiday'].sum()\n",
    "block_num_info['holidays'].fillna(0, inplace=True)\n",
    "\n",
    "block_num_info['off_days'] = date_df[date_df.off_day == True].groupby('date_block_num')['off_day'].sum()\n",
    "block_num_info['off_days'].fillna(0, inplace=True)\n",
    "\n",
    "block_num_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the initial training df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2554</td>\n",
       "      <td>1709.05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2555</td>\n",
       "      <td>1099.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  date_block_num  shop_id  item_id  item_price  item_cnt_day\n",
       "0  02.01.2013               0       59    22154      999.00           1.0\n",
       "1  03.01.2013               0       25     2552      899.00           1.0\n",
       "2  05.01.2013               0       25     2552      899.00          -1.0\n",
       "3  06.01.2013               0       25     2554     1709.05           1.0\n",
       "4  15.01.2013               0       25     2555     1099.00           1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, date, time\n",
    "\n",
    "# 'sales' is the input training dataframe\n",
    "#sales['date'] = pd.to_datetime(sales['date'])\n",
    "\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Money spent every month ( We see the seasonality!)\n",
    "plt.clf()\n",
    "total_transactions_monthly = sales[sales['item_cnt_day'] > 0].groupby('date_block_num')['item_price'].sum().reset_index(name = \"rubens\")\n",
    "sns.set_style(\"darkgrid\")\n",
    "total_transactions_monthly.plot(x='date_block_num', y='rubens', style='o')\n",
    "plt.title(\" money Spent vs month\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1609124, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>item_avg_price</th>\n",
       "      <th>month</th>\n",
       "      <th>shop_name</th>\n",
       "      <th>shop_type</th>\n",
       "      <th>city</th>\n",
       "      <th>time_wrt_utc</th>\n",
       "      <th>fed_subject</th>\n",
       "      <th>fed_dist</th>\n",
       "      <th>dist_from_moscow</th>\n",
       "      <th>weekends</th>\n",
       "      <th>holidays</th>\n",
       "      <th>off_days</th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>6.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1</td>\n",
       "      <td>!Якутск Орджоникидзе, 56 фран</td>\n",
       "      <td>OTH</td>\n",
       "      <td>Якутск</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Sakha Republic</td>\n",
       "      <td>Far East</td>\n",
       "      <td>8395.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1+1</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>1</td>\n",
       "      <td>!Якутск Орджоникидзе, 56 фран</td>\n",
       "      <td>OTH</td>\n",
       "      <td>Якутск</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Sakha Republic</td>\n",
       "      <td>Far East</td>\n",
       "      <td>8395.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1+1 (BD)</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>1</td>\n",
       "      <td>!Якутск Орджоникидзе, 56 фран</td>\n",
       "      <td>OTH</td>\n",
       "      <td>Якутск</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Sakha Republic</td>\n",
       "      <td>Far East</td>\n",
       "      <td>8395.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14</td>\n",
       "      <td>10 ЛЕТ СПУСТЯ</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1</td>\n",
       "      <td>!Якутск Орджоникидзе, 56 фран</td>\n",
       "      <td>OTH</td>\n",
       "      <td>Якутск</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Sakha Republic</td>\n",
       "      <td>Far East</td>\n",
       "      <td>8395.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14</td>\n",
       "      <td>100 МИЛЛИОНОВ ЕВРО</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>128.5</td>\n",
       "      <td>1</td>\n",
       "      <td>!Якутск Орджоникидзе, 56 фран</td>\n",
       "      <td>OTH</td>\n",
       "      <td>Якутск</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Sakha Republic</td>\n",
       "      <td>Far East</td>\n",
       "      <td>8395.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14</td>\n",
       "      <td>100 лучших произведений классики (mp3-CD) (Dig...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  shop_id  item_id  item_cnt_month  item_avg_price  month  \\\n",
       "0               0        0       32             6.0           221.0      1   \n",
       "1               0        0       33             3.0           347.0      1   \n",
       "2               0        0       35             1.0           247.0      1   \n",
       "3               0        0       43             1.0           221.0      1   \n",
       "4               0        0       51             2.0           128.5      1   \n",
       "\n",
       "                       shop_name shop_type    city  time_wrt_utc  \\\n",
       "0  !Якутск Орджоникидзе, 56 фран       OTH  Якутск           9.0   \n",
       "1  !Якутск Орджоникидзе, 56 фран       OTH  Якутск           9.0   \n",
       "2  !Якутск Орджоникидзе, 56 фран       OTH  Якутск           9.0   \n",
       "3  !Якутск Орджоникидзе, 56 фран       OTH  Якутск           9.0   \n",
       "4  !Якутск Орджоникидзе, 56 фран       OTH  Якутск           9.0   \n",
       "\n",
       "      fed_subject  fed_dist  dist_from_moscow  weekends  holidays  off_days  \\\n",
       "0  Sakha Republic  Far East            8395.0       8.0       7.0        14   \n",
       "1  Sakha Republic  Far East            8395.0       8.0       7.0        14   \n",
       "2  Sakha Republic  Far East            8395.0       8.0       7.0        14   \n",
       "3  Sakha Republic  Far East            8395.0       8.0       7.0        14   \n",
       "4  Sakha Republic  Far East            8395.0       8.0       7.0        14   \n",
       "\n",
       "                                           item_name  item_category_id  \n",
       "0                                                1+1                40  \n",
       "1                                           1+1 (BD)                37  \n",
       "2                                      10 ЛЕТ СПУСТЯ                40  \n",
       "3                                 100 МИЛЛИОНОВ ЕВРО                40  \n",
       "4  100 лучших произведений классики (mp3-CD) (Dig...                57  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove date column\n",
    "sales_monthly = sales #.drop(['date'], axis=1)\n",
    "\n",
    "# Aggregating item_cnt_day (summing) and item_price(averaging)\n",
    "agg_funcs = {'item_cnt_day':np.sum, 'item_price':np.mean}\n",
    "sales_monthly = sales_monthly.groupby(['date_block_num', 'shop_id', 'item_id']).agg(agg_funcs).reset_index()\n",
    "\n",
    "# rename the columns\n",
    "sales_monthly.rename(columns={'item_price':'item_avg_price', 'item_cnt_day':'item_cnt_month'}, inplace=True)\n",
    "\n",
    "# Adding month numbers (jan1, feb-2, march-3....dec-12)\n",
    "sales_monthly['month'] = (sales_monthly['date_block_num'] % 12)+1\n",
    "\n",
    "# Appending\n",
    "\n",
    "# shop information\n",
    "sales_monthly = pd.merge(sales_monthly, shops_df, on='shop_id', how='left')\n",
    "\n",
    "# block_num_info (temporal features)\n",
    "sales_monthly = pd.merge(sales_monthly, block_num_info, on='date_block_num', how='left')\n",
    "\n",
    "# item info\n",
    "sales_monthly = pd.merge(sales_monthly, items, on='item_id', how='left')\n",
    "\n",
    "print(sales_monthly.shape)\n",
    "\n",
    "sales_monthly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec\n",
    "Train the word2vec model on item-names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\purne\\Miniconda3\\envs\\py36\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "2019-02-18 22:16:47,424 : INFO : 'pattern' package not found; tag filters are not available for English\n",
      "2019-02-18 22:16:49,825 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-02-18 22:16:49,825 : INFO : collecting all words and their counts\n",
      "2019-02-18 22:16:49,825 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-02-18 22:16:49,837 : INFO : PROGRESS: at sentence #10000, processed 69241 words, keeping 10258 word types\n",
      "2019-02-18 22:16:49,847 : INFO : PROGRESS: at sentence #20000, processed 120597 words, keeping 17750 word types\n",
      "2019-02-18 22:16:49,850 : INFO : collected 19154 word types from a corpus of 133510 raw words and 22170 sentences\n",
      "2019-02-18 22:16:49,851 : INFO : Loading a fresh vocabulary\n",
      "2019-02-18 22:16:49,896 : INFO : min_count=3 retains 6583 unique words (34% of original 19154, drops 12571)\n",
      "2019-02-18 22:16:49,896 : INFO : min_count=3 leaves 117829 word corpus (88% of original 133510, drops 15681)\n",
      "2019-02-18 22:16:49,913 : INFO : deleting the raw counts dictionary of 19154 items\n",
      "2019-02-18 22:16:49,914 : INFO : sample=0.001 downsamples 43 most-common words\n",
      "2019-02-18 22:16:49,914 : INFO : downsampling leaves estimated 98479 word corpus (83.6% of prior 117829)\n",
      "2019-02-18 22:16:49,925 : INFO : estimated required memory for 6583 words and 50 dimensions: 5924700 bytes\n",
      "2019-02-18 22:16:49,926 : INFO : resetting layer weights\n",
      "2019-02-18 22:16:50,001 : INFO : training model with 6 workers on 6583 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-18 22:16:50,045 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:50,045 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:50,046 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:50,049 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:50,050 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:50,051 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:50,052 : INFO : EPOCH - 1 : training on 133510 raw words (98440 effective words) took 0.0s, 2467878 effective words/s\n",
      "2019-02-18 22:16:50,093 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:50,096 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:50,098 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:50,099 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:50,100 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:50,101 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:50,102 : INFO : EPOCH - 2 : training on 133510 raw words (98581 effective words) took 0.0s, 2475873 effective words/s\n",
      "2019-02-18 22:16:50,143 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:50,146 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:50,147 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:50,147 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:50,148 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:50,151 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:50,152 : INFO : EPOCH - 3 : training on 133510 raw words (98441 effective words) took 0.0s, 2473932 effective words/s\n",
      "2019-02-18 22:16:50,191 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:50,192 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:50,195 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:50,196 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:50,199 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:50,202 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:50,203 : INFO : EPOCH - 4 : training on 133510 raw words (98414 effective words) took 0.0s, 2392175 effective words/s\n",
      "2019-02-18 22:16:50,246 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:50,249 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:50,249 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:50,250 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:50,252 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:50,254 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:50,254 : INFO : EPOCH - 5 : training on 133510 raw words (98586 effective words) took 0.0s, 2401975 effective words/s\n",
      "2019-02-18 22:16:50,255 : INFO : training on a 667550 raw words (492462 effective words) took 0.3s, 1948520 effective words/s\n",
      "2019-02-18 22:16:50,255 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2019-02-18 22:16:50,255 : INFO : training model with 6 workers on 6583 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-02-18 22:16:50,301 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:50,304 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:50,305 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:50,306 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:50,309 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:50,310 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:50,310 : INFO : EPOCH - 1 : training on 133510 raw words (98491 effective words) took 0.0s, 2115988 effective words/s\n",
      "2019-02-18 22:16:50,355 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:50,356 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:50,356 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:50,360 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:50,360 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:50,361 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:50,362 : INFO : EPOCH - 2 : training on 133510 raw words (98462 effective words) took 0.0s, 2358165 effective words/s\n",
      "2019-02-18 22:16:50,406 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:50,409 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:50,410 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:50,411 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:50,411 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:50,413 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:50,413 : INFO : EPOCH - 3 : training on 133510 raw words (98473 effective words) took 0.0s, 2318070 effective words/s\n",
      "2019-02-18 22:16:50,454 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:50,456 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:50,458 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:50,460 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:50,462 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:50,464 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:50,464 : INFO : EPOCH - 4 : training on 133510 raw words (98417 effective words) took 0.0s, 2459942 effective words/s\n",
      "2019-02-18 22:16:50,505 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:50,509 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:50,510 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:50,511 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:50,514 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:50,515 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:50,515 : INFO : EPOCH - 5 : training on 133510 raw words (98394 effective words) took 0.0s, 2395051 effective words/s\n",
      "2019-02-18 22:16:50,557 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:50,558 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:50,558 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:50,561 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:50,563 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:50,564 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:50,565 : INFO : EPOCH - 6 : training on 133510 raw words (98580 effective words) took 0.0s, 2352460 effective words/s\n",
      "2019-02-18 22:16:50,610 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:50,611 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:50,611 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:50,615 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:50,616 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:50,616 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:50,617 : INFO : EPOCH - 7 : training on 133510 raw words (98246 effective words) took 0.0s, 2391093 effective words/s\n",
      "2019-02-18 22:16:50,659 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:50,659 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:50,664 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:50,666 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:50,667 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:50,668 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:50,669 : INFO : EPOCH - 8 : training on 133510 raw words (98447 effective words) took 0.0s, 2336443 effective words/s\n",
      "2019-02-18 22:16:50,714 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:50,715 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:50,716 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:50,718 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:50,719 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:50,720 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:50,720 : INFO : EPOCH - 9 : training on 133510 raw words (98392 effective words) took 0.0s, 2281787 effective words/s\n",
      "2019-02-18 22:16:50,763 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:50,767 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:50,768 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:50,768 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:50,771 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:50,772 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:50,773 : INFO : EPOCH - 10 : training on 133510 raw words (98435 effective words) took 0.0s, 2297793 effective words/s\n",
      "2019-02-18 22:16:50,814 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:50,817 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:50,820 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:50,820 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:50,823 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:50,826 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:50,827 : INFO : EPOCH - 11 : training on 133510 raw words (98359 effective words) took 0.0s, 2317539 effective words/s\n",
      "2019-02-18 22:16:50,870 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:50,870 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:50,871 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:50,874 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:50,875 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:50,877 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:50,877 : INFO : EPOCH - 12 : training on 133510 raw words (98491 effective words) took 0.0s, 2368175 effective words/s\n",
      "2019-02-18 22:16:50,923 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:50,925 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:50,926 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:50,927 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:50,927 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:50,928 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:50,928 : INFO : EPOCH - 13 : training on 133510 raw words (98423 effective words) took 0.0s, 2433438 effective words/s\n",
      "2019-02-18 22:16:50,970 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:50,972 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:50,974 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:50,977 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:50,979 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:50,980 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:50,980 : INFO : EPOCH - 14 : training on 133510 raw words (98364 effective words) took 0.0s, 2370149 effective words/s\n",
      "2019-02-18 22:16:51,023 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:51,027 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:51,028 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:51,029 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:51,031 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:51,032 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:51,032 : INFO : EPOCH - 15 : training on 133510 raw words (98543 effective words) took 0.0s, 2264900 effective words/s\n",
      "2019-02-18 22:16:51,074 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:51,077 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:51,079 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:51,079 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:51,083 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:51,083 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:51,083 : INFO : EPOCH - 16 : training on 133510 raw words (98563 effective words) took 0.0s, 2406041 effective words/s\n",
      "2019-02-18 22:16:51,124 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:51,125 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:51,128 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:51,129 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:51,131 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:51,133 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:51,133 : INFO : EPOCH - 17 : training on 133510 raw words (98516 effective words) took 0.0s, 2502509 effective words/s\n",
      "2019-02-18 22:16:51,175 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:51,180 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:51,181 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:51,181 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:51,182 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:51,185 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:51,186 : INFO : EPOCH - 18 : training on 133510 raw words (98498 effective words) took 0.0s, 2352448 effective words/s\n",
      "2019-02-18 22:16:51,228 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:51,229 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:51,231 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:51,232 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:51,235 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:51,236 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:51,236 : INFO : EPOCH - 19 : training on 133510 raw words (98410 effective words) took 0.0s, 2499511 effective words/s\n",
      "2019-02-18 22:16:51,278 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:51,281 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:51,282 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:51,283 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:51,285 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:51,287 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:51,287 : INFO : EPOCH - 20 : training on 133510 raw words (98430 effective words) took 0.0s, 2496560 effective words/s\n",
      "2019-02-18 22:16:51,330 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:51,332 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:51,333 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:51,333 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:51,336 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:51,337 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:51,338 : INFO : EPOCH - 21 : training on 133510 raw words (98489 effective words) took 0.0s, 2416193 effective words/s\n",
      "2019-02-18 22:16:51,379 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:51,382 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:51,383 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:51,384 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:51,386 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:51,387 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:51,388 : INFO : EPOCH - 22 : training on 133510 raw words (98456 effective words) took 0.0s, 2409618 effective words/s\n",
      "2019-02-18 22:16:51,426 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:51,433 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:51,435 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:51,436 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:51,437 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:51,438 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:51,438 : INFO : EPOCH - 23 : training on 133510 raw words (98474 effective words) took 0.0s, 2346571 effective words/s\n",
      "2019-02-18 22:16:51,480 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:51,481 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:51,483 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:51,485 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:51,486 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:51,488 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:51,489 : INFO : EPOCH - 24 : training on 133510 raw words (98501 effective words) took 0.0s, 2428471 effective words/s\n",
      "2019-02-18 22:16:51,532 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:51,538 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:51,539 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:51,539 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:51,540 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:51,542 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:51,542 : INFO : EPOCH - 25 : training on 133510 raw words (98361 effective words) took 0.0s, 2326008 effective words/s\n",
      "2019-02-18 22:16:51,586 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:51,587 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:51,589 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:51,591 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:51,592 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:51,593 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:51,594 : INFO : EPOCH - 26 : training on 133510 raw words (98467 effective words) took 0.0s, 2289488 effective words/s\n",
      "2019-02-18 22:16:51,637 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:51,641 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:51,642 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:51,643 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:51,645 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:51,646 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:51,646 : INFO : EPOCH - 27 : training on 133510 raw words (98405 effective words) took 0.0s, 2744889 effective words/s\n",
      "2019-02-18 22:16:51,691 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:51,691 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:51,692 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:51,696 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:51,696 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:51,697 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:51,697 : INFO : EPOCH - 28 : training on 133510 raw words (98440 effective words) took 0.0s, 2262032 effective words/s\n",
      "2019-02-18 22:16:51,740 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:51,745 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:51,745 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:51,746 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:51,748 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:51,749 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:51,749 : INFO : EPOCH - 29 : training on 133510 raw words (98449 effective words) took 0.0s, 2379758 effective words/s\n",
      "2019-02-18 22:16:51,788 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-02-18 22:16:51,790 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-02-18 22:16:51,793 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-02-18 22:16:51,793 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-02-18 22:16:51,797 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-02-18 22:16:51,798 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-02-18 22:16:51,799 : INFO : EPOCH - 30 : training on 133510 raw words (98616 effective words) took 0.0s, 3377254 effective words/s\n",
      "2019-02-18 22:16:51,799 : INFO : training on a 4005300 raw words (2953592 effective words) took 1.5s, 1913596 effective words/s\n",
      "2019-02-18 22:16:51,800 : INFO : saving Word2Vec object under ./word2vec/item_names_word2vec.model, separately None\n",
      "2019-02-18 22:16:51,800 : INFO : not storing attribute vectors_norm\n",
      "2019-02-18 22:16:51,801 : INFO : not storing attribute cum_table\n",
      "2019-02-18 22:16:51,833 : INFO : saved ./word2vec/item_names_word2vec.model\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Input to Word2Vec is ->\n",
    "# [['at', 't', 'worldwid', 'prepaid', 'phone', 'card'],\n",
    "#  ['pk', 'religi', 'cand', 'milagro', 'de', 'tepeyac'],\n",
    "#  ['jenna', 'bra', 'yelw', 'dsv', 'onli'],\n",
    "#  ['davinci', 'jenni', 'lind', 'stationari', 'crib', 'eboni'],\n",
    "#  ['slice', 'toaster', 'white', 'pk']] - > Array(Array(String))\n",
    "\n",
    "newpath = r'./word2vec' \n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "\n",
    "items = pd.read_csv(os.path.join(DATA_FOLDER, 'items.csv'))\n",
    "\n",
    "tokenized_item_names = list(items['item_name'].apply(tokenize))\n",
    "\n",
    "model = Word2Vec(\n",
    "    tokenized_item_names,\n",
    "    size = 50,\n",
    "    window = 5,\n",
    "    min_count = 3,\n",
    "    workers = 6)\n",
    "\n",
    "model.train(tokenized_item_names, total_examples = len(tokenized_item_names), epochs=30)\n",
    "model.save(\"./word2vec/item_names_word2vec.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>iv0</th>\n",
       "      <th>iv1</th>\n",
       "      <th>iv2</th>\n",
       "      <th>iv3</th>\n",
       "      <th>iv4</th>\n",
       "      <th>iv5</th>\n",
       "      <th>iv6</th>\n",
       "      <th>...</th>\n",
       "      <th>iv40</th>\n",
       "      <th>iv41</th>\n",
       "      <th>iv42</th>\n",
       "      <th>iv43</th>\n",
       "      <th>iv44</th>\n",
       "      <th>iv45</th>\n",
       "      <th>iv46</th>\n",
       "      <th>iv47</th>\n",
       "      <th>iv48</th>\n",
       "      <th>iv49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>! ВО ВЛАСТИ НАВАЖДЕНИЯ (ПЛАСТ.)         D</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.7016</td>\n",
       "      <td>-0.2077</td>\n",
       "      <td>0.3475</td>\n",
       "      <td>-0.9564</td>\n",
       "      <td>0.4632</td>\n",
       "      <td>0.2008</td>\n",
       "      <td>-0.5481</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3649</td>\n",
       "      <td>-0.2245</td>\n",
       "      <td>-1.1344</td>\n",
       "      <td>-0.1566</td>\n",
       "      <td>1.2741</td>\n",
       "      <td>0.9208</td>\n",
       "      <td>-0.7797</td>\n",
       "      <td>-0.4763</td>\n",
       "      <td>-0.5572</td>\n",
       "      <td>0.4777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!ABBYY FineReader 12 Professional Edition Full...</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>-10.2165</td>\n",
       "      <td>-1.2581</td>\n",
       "      <td>6.4800</td>\n",
       "      <td>2.1307</td>\n",
       "      <td>3.7471</td>\n",
       "      <td>13.2242</td>\n",
       "      <td>-2.4687</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4462</td>\n",
       "      <td>1.4264</td>\n",
       "      <td>-17.1839</td>\n",
       "      <td>-7.1674</td>\n",
       "      <td>0.6959</td>\n",
       "      <td>2.3287</td>\n",
       "      <td>-5.7547</td>\n",
       "      <td>2.5191</td>\n",
       "      <td>3.7157</td>\n",
       "      <td>1.7755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***В ЛУЧАХ СЛАВЫ   (UNV)                    D</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>3.5956</td>\n",
       "      <td>-0.1060</td>\n",
       "      <td>-1.3064</td>\n",
       "      <td>-2.3966</td>\n",
       "      <td>-0.7508</td>\n",
       "      <td>1.5329</td>\n",
       "      <td>-1.8026</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3443</td>\n",
       "      <td>-0.9587</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>-1.6738</td>\n",
       "      <td>-3.0662</td>\n",
       "      <td>1.9063</td>\n",
       "      <td>-0.5870</td>\n",
       "      <td>-2.5061</td>\n",
       "      <td>-4.3043</td>\n",
       "      <td>0.4823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>***ГОЛУБАЯ ВОЛНА  (Univ)                      D</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>0.4640</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.4052</td>\n",
       "      <td>0.2427</td>\n",
       "      <td>1.0238</td>\n",
       "      <td>0.8774</td>\n",
       "      <td>-0.0306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5998</td>\n",
       "      <td>0.3162</td>\n",
       "      <td>-1.4966</td>\n",
       "      <td>0.2640</td>\n",
       "      <td>1.4573</td>\n",
       "      <td>0.6094</td>\n",
       "      <td>-0.9060</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>-0.4682</td>\n",
       "      <td>0.2957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>***КОРОБКА (СТЕКЛО)                       D</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>-0.1306</td>\n",
       "      <td>0.9320</td>\n",
       "      <td>0.4177</td>\n",
       "      <td>0.3348</td>\n",
       "      <td>0.9776</td>\n",
       "      <td>1.3515</td>\n",
       "      <td>-1.0336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4669</td>\n",
       "      <td>0.2349</td>\n",
       "      <td>-2.7100</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>1.2365</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>-1.5777</td>\n",
       "      <td>0.1913</td>\n",
       "      <td>-0.3190</td>\n",
       "      <td>-0.3875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           item_name  item_id  \\\n",
       "0          ! ВО ВЛАСТИ НАВАЖДЕНИЯ (ПЛАСТ.)         D        0   \n",
       "1  !ABBYY FineReader 12 Professional Edition Full...        1   \n",
       "2      ***В ЛУЧАХ СЛАВЫ   (UNV)                    D        2   \n",
       "3    ***ГОЛУБАЯ ВОЛНА  (Univ)                      D        3   \n",
       "4        ***КОРОБКА (СТЕКЛО)                       D        4   \n",
       "\n",
       "   item_category_id      iv0     iv1     iv2     iv3     iv4      iv5     iv6  \\\n",
       "0                40   0.7016 -0.2077  0.3475 -0.9564  0.4632   0.2008 -0.5481   \n",
       "1                76 -10.2165 -1.2581  6.4800  2.1307  3.7471  13.2242 -2.4687   \n",
       "2                40   3.5956 -0.1060 -1.3064 -2.3966 -0.7508   1.5329 -1.8026   \n",
       "3                40   0.4640  0.1030  0.4052  0.2427  1.0238   0.8774 -0.0306   \n",
       "4                40  -0.1306  0.9320  0.4177  0.3348  0.9776   1.3515 -1.0336   \n",
       "\n",
       "    ...      iv40    iv41     iv42    iv43    iv44    iv45    iv46    iv47  \\\n",
       "0   ...    1.3649 -0.2245  -1.1344 -0.1566  1.2741  0.9208 -0.7797 -0.4763   \n",
       "1   ...    2.4462  1.4264 -17.1839 -7.1674  0.6959  2.3287 -5.7547  2.5191   \n",
       "2   ...    2.3443 -0.9587   0.2872 -1.6738 -3.0662  1.9063 -0.5870 -2.5061   \n",
       "3   ...    0.5998  0.3162  -1.4966  0.2640  1.4573  0.6094 -0.9060  0.0142   \n",
       "4   ...    0.4669  0.2349  -2.7100  0.0161  1.2365  0.2226 -1.5777  0.1913   \n",
       "\n",
       "     iv48    iv49  \n",
       "0 -0.5572  0.4777  \n",
       "1  3.7157  1.7755  \n",
       "2 -4.3043  0.4823  \n",
       "3 -0.4682  0.2957  \n",
       "4 -0.3190 -0.3875  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the items_vec_df. features -> ['iv1', 'iv2', 'iv3',......'iv100']\n",
    "\n",
    "items_vec_df = items\n",
    "items_vec_df['item_vector'] = items_vec_df['item_name'].apply(lambda x: w2v_vectorize(x, model))\n",
    "\n",
    "b = np.array(range(0,model.wv.vector_size))\n",
    "b = [str(x) for x in b]\n",
    "z = []\n",
    "for x in b:\n",
    "    z.append('iv'+x)\n",
    "\n",
    "temp = pd.DataFrame(items_vec_df.item_vector.tolist(), columns=z)\n",
    "items_vec_df.drop('item_vector', axis=1, inplace=True)\n",
    "items_vec_df = pd.concat([items_vec_df, temp], axis=1)\n",
    "\n",
    "items_vec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>iv0</th>\n",
       "      <th>iv1</th>\n",
       "      <th>iv2</th>\n",
       "      <th>iv3</th>\n",
       "      <th>iv4</th>\n",
       "      <th>iv5</th>\n",
       "      <th>iv6</th>\n",
       "      <th>iv7</th>\n",
       "      <th>iv8</th>\n",
       "      <th>...</th>\n",
       "      <th>iv40</th>\n",
       "      <th>iv41</th>\n",
       "      <th>iv42</th>\n",
       "      <th>iv43</th>\n",
       "      <th>iv44</th>\n",
       "      <th>iv45</th>\n",
       "      <th>iv46</th>\n",
       "      <th>iv47</th>\n",
       "      <th>iv48</th>\n",
       "      <th>iv49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7016</td>\n",
       "      <td>-0.2077</td>\n",
       "      <td>0.3475</td>\n",
       "      <td>-0.9564</td>\n",
       "      <td>0.4632</td>\n",
       "      <td>0.2008</td>\n",
       "      <td>-0.5481</td>\n",
       "      <td>-0.2007</td>\n",
       "      <td>-0.2543</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3649</td>\n",
       "      <td>-0.2245</td>\n",
       "      <td>-1.1344</td>\n",
       "      <td>-0.1566</td>\n",
       "      <td>1.2741</td>\n",
       "      <td>0.9208</td>\n",
       "      <td>-0.7797</td>\n",
       "      <td>-0.4763</td>\n",
       "      <td>-0.5572</td>\n",
       "      <td>0.4777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-10.2165</td>\n",
       "      <td>-1.2581</td>\n",
       "      <td>6.4800</td>\n",
       "      <td>2.1307</td>\n",
       "      <td>3.7471</td>\n",
       "      <td>13.2242</td>\n",
       "      <td>-2.4687</td>\n",
       "      <td>-12.7418</td>\n",
       "      <td>12.6134</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4462</td>\n",
       "      <td>1.4264</td>\n",
       "      <td>-17.1839</td>\n",
       "      <td>-7.1674</td>\n",
       "      <td>0.6959</td>\n",
       "      <td>2.3287</td>\n",
       "      <td>-5.7547</td>\n",
       "      <td>2.5191</td>\n",
       "      <td>3.7157</td>\n",
       "      <td>1.7755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.5956</td>\n",
       "      <td>-0.1060</td>\n",
       "      <td>-1.3064</td>\n",
       "      <td>-2.3966</td>\n",
       "      <td>-0.7508</td>\n",
       "      <td>1.5329</td>\n",
       "      <td>-1.8026</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>-2.1477</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3443</td>\n",
       "      <td>-0.9587</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>-1.6738</td>\n",
       "      <td>-3.0662</td>\n",
       "      <td>1.9063</td>\n",
       "      <td>-0.5870</td>\n",
       "      <td>-2.5061</td>\n",
       "      <td>-4.3043</td>\n",
       "      <td>0.4823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.4640</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.4052</td>\n",
       "      <td>0.2427</td>\n",
       "      <td>1.0238</td>\n",
       "      <td>0.8774</td>\n",
       "      <td>-0.0306</td>\n",
       "      <td>-0.0522</td>\n",
       "      <td>0.3401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5998</td>\n",
       "      <td>0.3162</td>\n",
       "      <td>-1.4966</td>\n",
       "      <td>0.2640</td>\n",
       "      <td>1.4573</td>\n",
       "      <td>0.6094</td>\n",
       "      <td>-0.9060</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>-0.4682</td>\n",
       "      <td>0.2957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.1306</td>\n",
       "      <td>0.9320</td>\n",
       "      <td>0.4177</td>\n",
       "      <td>0.3348</td>\n",
       "      <td>0.9776</td>\n",
       "      <td>1.3515</td>\n",
       "      <td>-1.0336</td>\n",
       "      <td>-0.8806</td>\n",
       "      <td>1.1659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4669</td>\n",
       "      <td>0.2349</td>\n",
       "      <td>-2.7100</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>1.2365</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>-1.5777</td>\n",
       "      <td>0.1913</td>\n",
       "      <td>-0.3190</td>\n",
       "      <td>-0.3875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id      iv0     iv1     iv2     iv3     iv4      iv5     iv6      iv7  \\\n",
       "0        0   0.7016 -0.2077  0.3475 -0.9564  0.4632   0.2008 -0.5481  -0.2007   \n",
       "1        1 -10.2165 -1.2581  6.4800  2.1307  3.7471  13.2242 -2.4687 -12.7418   \n",
       "2        2   3.5956 -0.1060 -1.3064 -2.3966 -0.7508   1.5329 -1.8026   0.4600   \n",
       "3        3   0.4640  0.1030  0.4052  0.2427  1.0238   0.8774 -0.0306  -0.0522   \n",
       "4        4  -0.1306  0.9320  0.4177  0.3348  0.9776   1.3515 -1.0336  -0.8806   \n",
       "\n",
       "       iv8   ...      iv40    iv41     iv42    iv43    iv44    iv45    iv46  \\\n",
       "0  -0.2543   ...    1.3649 -0.2245  -1.1344 -0.1566  1.2741  0.9208 -0.7797   \n",
       "1  12.6134   ...    2.4462  1.4264 -17.1839 -7.1674  0.6959  2.3287 -5.7547   \n",
       "2  -2.1477   ...    2.3443 -0.9587   0.2872 -1.6738 -3.0662  1.9063 -0.5870   \n",
       "3   0.3401   ...    0.5998  0.3162  -1.4966  0.2640  1.4573  0.6094 -0.9060   \n",
       "4   1.1659   ...    0.4669  0.2349  -2.7100  0.0161  1.2365  0.2226 -1.5777   \n",
       "\n",
       "     iv47    iv48    iv49  \n",
       "0 -0.4763 -0.5572  0.4777  \n",
       "1  2.5191  3.7157  1.7755  \n",
       "2 -2.5061 -4.3043  0.4823  \n",
       "3  0.0142 -0.4682  0.2957  \n",
       "4  0.1913 -0.3190 -0.3875  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_vec_df.drop(columns=[\"item_category_id\", \"item_name\"], inplace=True)\n",
    "items_vec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>item_avg_price</th>\n",
       "      <th>month</th>\n",
       "      <th>shop_name</th>\n",
       "      <th>shop_type</th>\n",
       "      <th>city</th>\n",
       "      <th>time_wrt_utc</th>\n",
       "      <th>...</th>\n",
       "      <th>iv40</th>\n",
       "      <th>iv41</th>\n",
       "      <th>iv42</th>\n",
       "      <th>iv43</th>\n",
       "      <th>iv44</th>\n",
       "      <th>iv45</th>\n",
       "      <th>iv46</th>\n",
       "      <th>iv47</th>\n",
       "      <th>iv48</th>\n",
       "      <th>iv49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>6.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1</td>\n",
       "      <td>!Якутск Орджоникидзе, 56 фран</td>\n",
       "      <td>OTH</td>\n",
       "      <td>Якутск</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3566</td>\n",
       "      <td>0.5502</td>\n",
       "      <td>-0.8563</td>\n",
       "      <td>-0.2069</td>\n",
       "      <td>1.7178</td>\n",
       "      <td>0.2810</td>\n",
       "      <td>-1.0862</td>\n",
       "      <td>-0.0453</td>\n",
       "      <td>-0.5737</td>\n",
       "      <td>0.0987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>1</td>\n",
       "      <td>!Якутск Орджоникидзе, 56 фран</td>\n",
       "      <td>OTH</td>\n",
       "      <td>Якутск</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5775</td>\n",
       "      <td>-1.4220</td>\n",
       "      <td>-3.6628</td>\n",
       "      <td>-1.5782</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>1.6149</td>\n",
       "      <td>-2.9767</td>\n",
       "      <td>0.0823</td>\n",
       "      <td>-1.0935</td>\n",
       "      <td>-0.4610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>1</td>\n",
       "      <td>!Якутск Орджоникидзе, 56 фран</td>\n",
       "      <td>OTH</td>\n",
       "      <td>Якутск</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8549</td>\n",
       "      <td>1.8292</td>\n",
       "      <td>-1.9485</td>\n",
       "      <td>-0.1621</td>\n",
       "      <td>1.0428</td>\n",
       "      <td>4.4827</td>\n",
       "      <td>-1.8161</td>\n",
       "      <td>-1.2985</td>\n",
       "      <td>-3.9845</td>\n",
       "      <td>-0.8285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1</td>\n",
       "      <td>!Якутск Орджоникидзе, 56 фран</td>\n",
       "      <td>OTH</td>\n",
       "      <td>Якутск</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1692</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>-1.2545</td>\n",
       "      <td>0.7963</td>\n",
       "      <td>1.5012</td>\n",
       "      <td>1.2882</td>\n",
       "      <td>1.9808</td>\n",
       "      <td>-0.4359</td>\n",
       "      <td>-0.5554</td>\n",
       "      <td>-1.3967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>128.5</td>\n",
       "      <td>1</td>\n",
       "      <td>!Якутск Орджоникидзе, 56 фран</td>\n",
       "      <td>OTH</td>\n",
       "      <td>Якутск</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4048</td>\n",
       "      <td>0.8934</td>\n",
       "      <td>0.1243</td>\n",
       "      <td>3.5812</td>\n",
       "      <td>8.7516</td>\n",
       "      <td>10.7346</td>\n",
       "      <td>7.4210</td>\n",
       "      <td>3.0092</td>\n",
       "      <td>-0.6006</td>\n",
       "      <td>-5.9277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  shop_id  item_id  item_cnt_month  item_avg_price  month  \\\n",
       "0               0        0       32             6.0           221.0      1   \n",
       "1               0        0       33             3.0           347.0      1   \n",
       "2               0        0       35             1.0           247.0      1   \n",
       "3               0        0       43             1.0           221.0      1   \n",
       "4               0        0       51             2.0           128.5      1   \n",
       "\n",
       "                       shop_name shop_type    city  time_wrt_utc   ...    \\\n",
       "0  !Якутск Орджоникидзе, 56 фран       OTH  Якутск           9.0   ...     \n",
       "1  !Якутск Орджоникидзе, 56 фран       OTH  Якутск           9.0   ...     \n",
       "2  !Якутск Орджоникидзе, 56 фран       OTH  Якутск           9.0   ...     \n",
       "3  !Якутск Орджоникидзе, 56 фран       OTH  Якутск           9.0   ...     \n",
       "4  !Якутск Орджоникидзе, 56 фран       OTH  Якутск           9.0   ...     \n",
       "\n",
       "     iv40    iv41    iv42    iv43    iv44     iv45    iv46    iv47    iv48  \\\n",
       "0  0.3566  0.5502 -0.8563 -0.2069  1.7178   0.2810 -1.0862 -0.0453 -0.5737   \n",
       "1  0.5775 -1.4220 -3.6628 -1.5782  3.0000   1.6149 -2.9767  0.0823 -1.0935   \n",
       "2  0.8549  1.8292 -1.9485 -0.1621  1.0428   4.4827 -1.8161 -1.2985 -3.9845   \n",
       "3 -0.1692  0.4924 -1.2545  0.7963  1.5012   1.2882  1.9808 -0.4359 -0.5554   \n",
       "4  1.4048  0.8934  0.1243  3.5812  8.7516  10.7346  7.4210  3.0092 -0.6006   \n",
       "\n",
       "     iv49  \n",
       "0  0.0987  \n",
       "1 -0.4610  \n",
       "2 -0.8285  \n",
       "3 -1.3967  \n",
       "4 -5.9277  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_monthly_ext = pd.merge(sales_monthly, items_vec_df, on='item_id', how='left')\n",
    "sales_monthly_ext.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "1. In-store transactions are decreasing every month !!\n",
    "\n",
    "2. Online sales are increasing !!\n",
    "\n",
    "3. The total transactions are decreasing every month.... this is surprising !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Online vs In-store sales\n",
    "\n",
    "# phy_stores_list = list(set(shops_df.shop_id) ^ set([12,55]))\n",
    "\n",
    "# plt.clf()\n",
    "# total_transactions_monthly = sales_monthly.groupby('date_block_num').size().reset_index(name = \"trans_count\")\n",
    "# sns.set_style(\"darkgrid\")\n",
    "# total_transactions_monthly.plot(x='date_block_num', y='trans_count', style='o')\n",
    "# plt.title(\" Total Transactions vs month\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.clf()\n",
    "# online_transactions_monthly = sales_monthly[sales_monthly['shop_id'].isin([12,55])].groupby('date_block_num').size().reset_index(name = \"trans_count\")\n",
    "# sns.set_style(\"darkgrid\")\n",
    "# online_transactions_monthly.plot(x='date_block_num', y='trans_count', style='o')\n",
    "# plt.title(\"Online Transactions vs month\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.clf()\n",
    "# instore_transactions_monthly = sales_monthly[sales_monthly['shop_id'].isin(phy_stores_list)].groupby('date_block_num').size().reset_index(name = \"trans_count\")\n",
    "# sns.set_style(\"darkgrid\")\n",
    "# instore_transactions_monthly.plot(x='date_block_num', y='trans_count', style='o')\n",
    "# plt.title(\"In Store Transactions vs month\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# x = sales_monthly.groupby('date_block_num')['item_id'].nunique().reset_index()\n",
    "# x.rename(columns={'item_id':'num_items'}, inplace=True)\n",
    "\n",
    "\n",
    "# plt.clf()\n",
    "# sns.set_style(\"darkgrid\")\n",
    "# x.plot(x='date_block_num', y='num_items', style='o')\n",
    "# plt.title(\"Unique items every month\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.clf()\n",
    "\n",
    "# # Plot the shopi-transactions\n",
    "# sns.set_color_codes(\"muted\")\n",
    "# f, ax = plt.subplots(figsize=(8, 12))\n",
    "# sns.set(font_scale=1.5)\n",
    "\n",
    "# sns.countplot(y=\"shop_id\", data=sales_monthly, palette=\"Greens_d\", order = sales_monthly['shop_id'].value_counts().index)\n",
    "\n",
    "# plt.title(\"Distribution of transactions across shops\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sales_monthly.groupby(\"shop_id\")['item_id'].nunique()\n",
    "# test.groupby(\"shop_id\").size().reset_index(name = \"trans_count_for_the_shop\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.clf()\n",
    "\n",
    "# # Plot the shopid-transactions\n",
    "# sns.set_color_codes(\"muted\")\n",
    "# f, ax = plt.subplots(figsize=(10, 22))\n",
    "# sns.set(font_scale=1.5)\n",
    "\n",
    "# sns.countplot(y=\"item_category_id\", data=sales_monthly, palette=\"Greens_d\",\n",
    "#               order = sales_monthly['item_category_id'].value_counts().index)\n",
    "\n",
    "# plt.title(\"Distribution of item-categories in the monthly transaction data\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# item_catgs = [51, 10, 1, 50, 0, 52, 53, 48, 27, 36, 18, 46, 74, 26, 34, 68, 9, 44, 13,\n",
    "#               17, 80, 8, 81, 39, 82, 54, 42, 79, 16, 71, 4, 60, 76, 78]\n",
    "# plt.clf()\n",
    "\n",
    "# # Plot the shopi-transactions\n",
    "# sns.set_color_codes(\"muted\")\n",
    "# f, ax = plt.subplots(figsize=(10, 22))\n",
    "# sns.set(font_scale=1.5)\n",
    "# df = sales_monthly[sales_monthly['item_category_id'].isin(item_catgs)]\n",
    "\n",
    "# sns.countplot(y=\"item_category_id\", data=sales_monthly[sales_monthly['item_category_id'].isin(item_catgs)],\n",
    "#               palette=\"Greens_d\", order = df['item_category_id'].value_counts().index)\n",
    "# plt.title(\"Distribution of Item categories( with count < 1650) in monthly transaction data\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# items.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# item_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\purne\\Miniconda3\\envs\\py36\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit, train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer, LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date_block_num', 'shop_id', 'item_id', 'item_cnt_month', 'item_avg_price', 'month', 'shop_name', 'shop_type', 'city', 'time_wrt_utc', 'fed_subject', 'fed_dist', 'dist_from_moscow', 'weekends', 'holidays', 'off_days', 'item_name', 'item_category_id', 'iv0', 'iv1', 'iv2', 'iv3', 'iv4', 'iv5', 'iv6', 'iv7', 'iv8', 'iv9', 'iv10', 'iv11', 'iv12', 'iv13', 'iv14', 'iv15', 'iv16', 'iv17', 'iv18', 'iv19', 'iv20', 'iv21', 'iv22', 'iv23', 'iv24', 'iv25', 'iv26', 'iv27', 'iv28', 'iv29', 'iv30', 'iv31', 'iv32', 'iv33', 'iv34', 'iv35', 'iv36', 'iv37', 'iv38', 'iv39', 'iv40', 'iv41', 'iv42', 'iv43', 'iv44', 'iv45', 'iv46', 'iv47', 'iv48', 'iv49']\n"
     ]
    }
   ],
   "source": [
    "print(sales_monthly_ext.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>item_avg_price</th>\n",
       "      <th>month</th>\n",
       "      <th>shop_name</th>\n",
       "      <th>shop_type</th>\n",
       "      <th>city</th>\n",
       "      <th>time_wrt_utc</th>\n",
       "      <th>...</th>\n",
       "      <th>iv40</th>\n",
       "      <th>iv41</th>\n",
       "      <th>iv42</th>\n",
       "      <th>iv43</th>\n",
       "      <th>iv44</th>\n",
       "      <th>iv45</th>\n",
       "      <th>iv46</th>\n",
       "      <th>iv47</th>\n",
       "      <th>iv48</th>\n",
       "      <th>iv49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>6.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1</td>\n",
       "      <td>!Якутск Орджоникидзе, 56 фран</td>\n",
       "      <td>OTH</td>\n",
       "      <td>Якутск</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3566</td>\n",
       "      <td>0.5502</td>\n",
       "      <td>-0.8563</td>\n",
       "      <td>-0.2069</td>\n",
       "      <td>1.7178</td>\n",
       "      <td>0.2810</td>\n",
       "      <td>-1.0862</td>\n",
       "      <td>-0.0453</td>\n",
       "      <td>-0.5737</td>\n",
       "      <td>0.0987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>1</td>\n",
       "      <td>!Якутск Орджоникидзе, 56 фран</td>\n",
       "      <td>OTH</td>\n",
       "      <td>Якутск</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5775</td>\n",
       "      <td>-1.4220</td>\n",
       "      <td>-3.6628</td>\n",
       "      <td>-1.5782</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>1.6149</td>\n",
       "      <td>-2.9767</td>\n",
       "      <td>0.0823</td>\n",
       "      <td>-1.0935</td>\n",
       "      <td>-0.4610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>1</td>\n",
       "      <td>!Якутск Орджоникидзе, 56 фран</td>\n",
       "      <td>OTH</td>\n",
       "      <td>Якутск</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8549</td>\n",
       "      <td>1.8292</td>\n",
       "      <td>-1.9485</td>\n",
       "      <td>-0.1621</td>\n",
       "      <td>1.0428</td>\n",
       "      <td>4.4827</td>\n",
       "      <td>-1.8161</td>\n",
       "      <td>-1.2985</td>\n",
       "      <td>-3.9845</td>\n",
       "      <td>-0.8285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>1</td>\n",
       "      <td>!Якутск Орджоникидзе, 56 фран</td>\n",
       "      <td>OTH</td>\n",
       "      <td>Якутск</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1692</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>-1.2545</td>\n",
       "      <td>0.7963</td>\n",
       "      <td>1.5012</td>\n",
       "      <td>1.2882</td>\n",
       "      <td>1.9808</td>\n",
       "      <td>-0.4359</td>\n",
       "      <td>-0.5554</td>\n",
       "      <td>-1.3967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num shop_id  item_id  item_cnt_month  item_avg_price month  \\\n",
       "0               0       0       32             6.0           221.0     1   \n",
       "1               0       0       33             3.0           347.0     1   \n",
       "2               0       0       35             1.0           247.0     1   \n",
       "3               0       0       43             1.0           221.0     1   \n",
       "\n",
       "                       shop_name shop_type    city  time_wrt_utc   ...    \\\n",
       "0  !Якутск Орджоникидзе, 56 фран       OTH  Якутск           9.0   ...     \n",
       "1  !Якутск Орджоникидзе, 56 фран       OTH  Якутск           9.0   ...     \n",
       "2  !Якутск Орджоникидзе, 56 фран       OTH  Якутск           9.0   ...     \n",
       "3  !Якутск Орджоникидзе, 56 фран       OTH  Якутск           9.0   ...     \n",
       "\n",
       "     iv40    iv41    iv42    iv43    iv44    iv45    iv46    iv47    iv48  \\\n",
       "0  0.3566  0.5502 -0.8563 -0.2069  1.7178  0.2810 -1.0862 -0.0453 -0.5737   \n",
       "1  0.5775 -1.4220 -3.6628 -1.5782  3.0000  1.6149 -2.9767  0.0823 -1.0935   \n",
       "2  0.8549  1.8292 -1.9485 -0.1621  1.0428  4.4827 -1.8161 -1.2985 -3.9845   \n",
       "3 -0.1692  0.4924 -1.2545  0.7963  1.5012  1.2882  1.9808 -0.4359 -0.5554   \n",
       "\n",
       "     iv49  \n",
       "0  0.0987  \n",
       "1 -0.4610  \n",
       "2 -0.8285  \n",
       "3 -1.3967  \n",
       "\n",
       "[4 rows x 68 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature  List  \n",
    "\n",
    "numeric_var = list([\"holidays\", \"off_days\",\"weekends\"]) + z # \"dist_from_moscow\"\n",
    "categ_var = list(['shop_id' , 'item_category_id', 'month']) # 'item_id', 'shop_type', 'time_wrt_utc', 'city', 'fed_subject', 'fed_dist'\n",
    "text_var  = list(['item_name']) #'shop_name'\n",
    "\n",
    "features = numeric_var + categ_var + text_var\n",
    "\n",
    "target_var = list(['item_cnt_month'])\n",
    "\n",
    "sales_monthly_ext[categ_var] = sales_monthly_ext[categ_var].apply(lambda x: x.astype('category'))\n",
    "sales_monthly_ext[numeric_var] = sales_monthly_ext[numeric_var].apply(lambda x: pd.to_numeric(x, downcast='float'))\n",
    "sales_monthly_ext[text_var] = sales_monthly_ext[text_var].apply(lambda x: x.astype('str'))\n",
    "\n",
    "sales_monthly_ext.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1302044, 60)\n",
      "(41390, 60)\n"
     ]
    }
   ],
   "source": [
    "data = sales_monthly_ext[features + target_var + list([\"date_block_num\", \"item_id\"])]\n",
    "\n",
    "data.head()\n",
    "\n",
    "vald = data[data.date_block_num == 25]\n",
    "train = data[data.date_block_num < 25]\n",
    "\n",
    "print(train.shape)\n",
    "print(vald.shape)\n",
    "\n",
    "y_train = train[target_var]\n",
    "x_train = train[features]\n",
    "\n",
    "y_vald = vald[target_var]\n",
    "x_vald = vald[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline model - A simple model which takes the average of the sales from last 4 months for each shop-item pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.7836917129741483\n",
      "Mean Squared Error: 48.620367238463395\n",
      "Root Mean Squared Error: 6.972830647481939\n",
      "\n",
      "Avg. count for each shop-item pair: 2.0342594829669003\n",
      "MAPE is 87.68 percent of avg_scan_count\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "df = train[train.date_block_num.isin([21, 22, 23, 24])][['shop_id', 'item_id', 'date_block_num', 'item_cnt_month']]\n",
    "df1 = df.groupby(['shop_id', 'item_id'])['item_cnt_month'].mean().reset_index(name=\"avg_item_cnt\")\n",
    "df1['avg_item_cnt'] = df1['avg_item_cnt'].apply(np.round)\n",
    "\n",
    "pred = pd.merge(vald, df1, on=['shop_id', 'item_id'], how='left')\n",
    "pred = pred[['shop_id', 'item_id', 'avg_item_cnt', 'item_cnt_month']]\n",
    "pred = pred['avg_item_cnt'].fillna(np.round(pred.avg_item_cnt.mean()))\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(vald.item_cnt_month, pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(vald.item_cnt_month, pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(vald.item_cnt_month, pred)))\n",
    "\n",
    "print(\"\\nAvg. count for each shop-item pair: {}\".format(vald.item_cnt_month.mean()))\n",
    "\n",
    "pct = metrics.mean_absolute_error(vald.item_cnt_month, pred) / vald.item_cnt_month.mean() * 100\n",
    "print(\"MAPE is {} percent of avg_scan_count\".format(np.round(pct,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 'How have the items been chosen for the test set? '.\n",
    "###### There are 5100 items in the test set out of which 4737 appear in the training data; 363 are not in the training data. Smilar split can appear in the private-test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: [      0       1       2 ... 1448990 1448991 1448992] len: 1448993\n",
      "Test: [1448993 1448994 1448995 ... 1480899 1480900 1480901] len: 31909\n",
      "\n",
      "\n",
      "\n",
      "Train: [      0       1       2 ... 1480899 1480900 1480901] len: 1480902\n",
      "Test: [1480902 1480903 1480904 ... 1514426 1514427 1514428] len: 33527\n",
      "\n",
      "\n",
      "\n",
      "Train: [      0       1       2 ... 1514426 1514427 1514428] len: 1514429\n",
      "Test: [1514429 1514430 1514431 ... 1547912 1547913 1547914] len: 33486\n",
      "\n",
      "\n",
      "\n",
      "Train: [      0       1       2 ... 1547912 1547913 1547914] len: 1547915\n",
      "Test: [1547915 1547916 1547917 ... 1577590 1577591 1577592] len: 29678\n",
      "\n",
      "\n",
      "\n",
      "Train: [      0       1       2 ... 1577590 1577591 1577592] len: 1577593\n",
      "Test: [1577593 1577594 1577595 ... 1609121 1609122 1609123] len: 31531\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define a custom cross-validator\n",
    "from sklearn.model_selection import BaseCrossValidator\n",
    "\n",
    "class CustomCVSplit(BaseCrossValidator):\n",
    "    def __init__(self, n_splits=3):\n",
    "        self.n_splits = n_splits\n",
    "    \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        L = len(groups.unique())\n",
    "        assert self.n_splits < L\n",
    "\n",
    "        start_block_num = L - self.n_splits\n",
    "        end_block_num = L-1\n",
    "        \n",
    "        for i in range(start_block_num, end_block_num+1):\n",
    "            test_index = groups[groups == i].index\n",
    "            train_index = groups[groups.isin(list(range(0,i)))].index\n",
    "            yield np.asarray(train_index), np.asarray(test_index)\n",
    "    \n",
    "    def get_n_splits(self, X, y=None, groups=None):\n",
    "        return self.n_splits\n",
    "    \n",
    "# testing the cv\n",
    "groups = data.date_block_num\n",
    "cv = CustomCVSplit(n_splits=5)\n",
    "i=0\n",
    "for train,test in cv.split(data, np.asarray(data), groups=groups):\n",
    "    i+=1\n",
    "    print(\"Train: {} len: {}\".format(train, len(train)))\n",
    "    print(\"Test: {} len: {}\".format(test, len(test)))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TypeSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, dtype):\n",
    "        self.dtype = dtype\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        return X.select_dtypes(include=[self.dtype])\n",
    "        \n",
    "        \n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column_list):\n",
    "        self.column_list = column_list   \n",
    "    def fit(self, X, y=None):\n",
    "        return self   \n",
    "    def transform(self, X):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        return X[self.column_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# DeepLearning\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# define base model\n",
    "def deep_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(159, input_dim=159, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(10, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "dnn = KerasRegressor(build_fn=deep_model, epochs=1000, batch_size=5000, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rand_forest_regressor = RandomForestRegressor(n_estimators=5, random_state=0, max_depth=25 , n_jobs=-1, verbose=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelines\n",
    "one_hot_encode = Pipeline([\n",
    "    ('extract_columns', ColumnSelector(['shop_id', 'month'])),\n",
    "    ('one_hot_encoding', OneHotEncoder())\n",
    "])\n",
    "\n",
    "\n",
    "# random-forest features\n",
    "rand_forest_feats = FeatureUnion([\n",
    "    ('numeric_feats', TypeSelector(dtype=np.number)),\n",
    "    ('one_hot_encoded_feats', one_hot_encode)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shop_name             object\n",
      "shop_id                int64\n",
      "shop_type           category\n",
      "city                category\n",
      "time_wrt_utc         float64\n",
      "fed_subject         category\n",
      "fed_dist            category\n",
      "dist_from_moscow     float64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "66\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "# print(shops_df.dtypes)\n",
    "# print(\"\\n\")\n",
    "# print(len(shops_df.shop_type.unique()) +\n",
    "#       len(shops_df.city.unique()) +\n",
    "#       len(shops_df.fed_subject.unique()) +\n",
    "#       len(shops_df.fed_dist.unique())\n",
    "#      )\n",
    "\n",
    "# print(len(shops_df.shop_id.unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random-forest pipeline\n",
    "rand_forest_pipeline = Pipeline([\n",
    "    ('rand_forest_feats',rand_forest_feats),\n",
    "    ('rand_forest_regressor', rand_forest_regressor)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module sklearn.externals.joblib.parallel in sklearn.externals.joblib:\n",
      "\n",
      "NAME\n",
      "    sklearn.externals.joblib.parallel - Helpers for embarrassingly parallel code.\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        BatchCompletionCallBack\n",
      "        BatchedCalls\n",
      "    sklearn.externals.joblib.logger.Logger(builtins.object)\n",
      "        Parallel\n",
      "    \n",
      "    class BatchCompletionCallBack(builtins.object)\n",
      "     |  Callback used by joblib.Parallel's multiprocessing backend.\n",
      "     |  \n",
      "     |  This callable is executed by the parent process whenever a worker process\n",
      "     |  has returned the results of a batch of tasks.\n",
      "     |  \n",
      "     |  It is used for progress reporting, to update estimate of the batch\n",
      "     |  processing duration and to schedule the next batch of tasks to be\n",
      "     |  processed.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, out)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  __init__(self, dispatch_timestamp, batch_size, parallel)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class BatchedCalls(builtins.object)\n",
      "     |  Wrap a sequence of (func, args, kwargs) tuples as a single callable\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  __init__(self, iterator_slice)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Parallel(sklearn.externals.joblib.logger.Logger)\n",
      "     |  Helper class for readable parallel mapping.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  -----------\n",
      "     |  n_jobs: int, default: 1\n",
      "     |      The maximum number of concurrently running jobs, such as the number\n",
      "     |      of Python worker processes when backend=\"multiprocessing\"\n",
      "     |      or the size of the thread-pool when backend=\"threading\".\n",
      "     |      If -1 all CPUs are used. If 1 is given, no parallel computing code\n",
      "     |      is used at all, which is useful for debugging. For n_jobs below -1,\n",
      "     |      (n_cpus + 1 + n_jobs) are used. Thus for n_jobs = -2, all\n",
      "     |      CPUs but one are used.\n",
      "     |  backend: str, ParallelBackendBase instance or None,                 default: 'multiprocessing'\n",
      "     |      Specify the parallelization backend implementation.\n",
      "     |      Supported backends are:\n",
      "     |  \n",
      "     |      - \"multiprocessing\" used by default, can induce some\n",
      "     |        communication and memory overhead when exchanging input and\n",
      "     |        output data with the worker Python processes.\n",
      "     |      - \"threading\" is a very low-overhead backend but it suffers\n",
      "     |        from the Python Global Interpreter Lock if the called function\n",
      "     |        relies a lot on Python objects. \"threading\" is mostly useful\n",
      "     |        when the execution bottleneck is a compiled extension that\n",
      "     |        explicitly releases the GIL (for instance a Cython loop wrapped\n",
      "     |        in a \"with nogil\" block or an expensive call to a library such\n",
      "     |        as NumPy).\n",
      "     |      - finally, you can register backends by calling\n",
      "     |        register_parallel_backend. This will allow you to implement\n",
      "     |        a backend of your liking.\n",
      "     |  verbose: int, optional\n",
      "     |      The verbosity level: if non zero, progress messages are\n",
      "     |      printed. Above 50, the output is sent to stdout.\n",
      "     |      The frequency of the messages increases with the verbosity level.\n",
      "     |      If it more than 10, all iterations are reported.\n",
      "     |  timeout: float, optional\n",
      "     |      Timeout limit for each task to complete.  If any task takes longer\n",
      "     |      a TimeOutError will be raised. Only applied when n_jobs != 1\n",
      "     |  pre_dispatch: {'all', integer, or expression, as in '3*n_jobs'}\n",
      "     |      The number of batches (of tasks) to be pre-dispatched.\n",
      "     |      Default is '2*n_jobs'. When batch_size=\"auto\" this is reasonable\n",
      "     |      default and the multiprocessing workers should never starve.\n",
      "     |  batch_size: int or 'auto', default: 'auto'\n",
      "     |      The number of atomic tasks to dispatch at once to each\n",
      "     |      worker. When individual evaluations are very fast, multiprocessing\n",
      "     |      can be slower than sequential computation because of the overhead.\n",
      "     |      Batching fast computations together can mitigate this.\n",
      "     |      The ``'auto'`` strategy keeps track of the time it takes for a batch\n",
      "     |      to complete, and dynamically adjusts the batch size to keep the time\n",
      "     |      on the order of half a second, using a heuristic. The initial batch\n",
      "     |      size is 1.\n",
      "     |      ``batch_size=\"auto\"`` with ``backend=\"threading\"`` will dispatch\n",
      "     |      batches of a single task at a time as the threading backend has\n",
      "     |      very little overhead and using larger batch size has not proved to\n",
      "     |      bring any gain in that case.\n",
      "     |  temp_folder: str, optional\n",
      "     |      Folder to be used by the pool for memmaping large arrays\n",
      "     |      for sharing memory with worker processes. If None, this will try in\n",
      "     |      order:\n",
      "     |  \n",
      "     |      - a folder pointed by the JOBLIB_TEMP_FOLDER environment\n",
      "     |        variable,\n",
      "     |      - /dev/shm if the folder exists and is writable: this is a\n",
      "     |        RAMdisk filesystem available by default on modern Linux\n",
      "     |        distributions,\n",
      "     |      - the default system temporary folder that can be\n",
      "     |        overridden with TMP, TMPDIR or TEMP environment\n",
      "     |        variables, typically /tmp under Unix operating systems.\n",
      "     |  \n",
      "     |      Only active when backend=\"multiprocessing\".\n",
      "     |  max_nbytes int, str, or None, optional, 1M by default\n",
      "     |      Threshold on the size of arrays passed to the workers that\n",
      "     |      triggers automated memory mapping in temp_folder. Can be an int\n",
      "     |      in Bytes, or a human-readable string, e.g., '1M' for 1 megabyte.\n",
      "     |      Use None to disable memmaping of large arrays.\n",
      "     |      Only active when backend=\"multiprocessing\".\n",
      "     |  mmap_mode: {None, 'r+', 'r', 'w+', 'c'}\n",
      "     |      Memmapping mode for numpy arrays passed to workers.\n",
      "     |      See 'max_nbytes' parameter documentation for more details.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  \n",
      "     |  This object uses the multiprocessing module to compute in\n",
      "     |  parallel the application of a function to many different\n",
      "     |  arguments. The main functionality it brings in addition to\n",
      "     |  using the raw multiprocessing API are (see examples for details):\n",
      "     |  \n",
      "     |  * More readable code, in particular since it avoids\n",
      "     |    constructing list of arguments.\n",
      "     |  \n",
      "     |  * Easier debugging:\n",
      "     |      - informative tracebacks even when the error happens on\n",
      "     |        the client side\n",
      "     |      - using 'n_jobs=1' enables to turn off parallel computing\n",
      "     |        for debugging without changing the codepath\n",
      "     |      - early capture of pickling errors\n",
      "     |  \n",
      "     |  * An optional progress meter.\n",
      "     |  \n",
      "     |  * Interruption of multiprocesses jobs with 'Ctrl-C'\n",
      "     |  \n",
      "     |  * Flexible pickling control for the communication to and from\n",
      "     |    the worker processes.\n",
      "     |  \n",
      "     |  * Ability to use shared memory efficiently with worker\n",
      "     |    processes for large numpy-based datastructures.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  \n",
      "     |  A simple example:\n",
      "     |  \n",
      "     |  >>> from math import sqrt\n",
      "     |  >>> from sklearn.externals.joblib import Parallel, delayed\n",
      "     |  >>> Parallel(n_jobs=1)(delayed(sqrt)(i**2) for i in range(10))\n",
      "     |  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]\n",
      "     |  \n",
      "     |  Reshaping the output when the function has several return\n",
      "     |  values:\n",
      "     |  \n",
      "     |  >>> from math import modf\n",
      "     |  >>> from sklearn.externals.joblib import Parallel, delayed\n",
      "     |  >>> r = Parallel(n_jobs=1)(delayed(modf)(i/2.) for i in range(10))\n",
      "     |  >>> res, i = zip(*r)\n",
      "     |  >>> res\n",
      "     |  (0.0, 0.5, 0.0, 0.5, 0.0, 0.5, 0.0, 0.5, 0.0, 0.5)\n",
      "     |  >>> i\n",
      "     |  (0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 4.0)\n",
      "     |  \n",
      "     |  The progress meter: the higher the value of `verbose`, the more\n",
      "     |  messages:\n",
      "     |  \n",
      "     |  >>> from time import sleep\n",
      "     |  >>> from sklearn.externals.joblib import Parallel, delayed\n",
      "     |  >>> r = Parallel(n_jobs=2, verbose=5)(delayed(sleep)(.1) for _ in range(10)) #doctest: +SKIP\n",
      "     |  [Parallel(n_jobs=2)]: Done   1 out of  10 | elapsed:    0.1s remaining:    0.9s\n",
      "     |  [Parallel(n_jobs=2)]: Done   3 out of  10 | elapsed:    0.2s remaining:    0.5s\n",
      "     |  [Parallel(n_jobs=2)]: Done   6 out of  10 | elapsed:    0.3s remaining:    0.2s\n",
      "     |  [Parallel(n_jobs=2)]: Done   9 out of  10 | elapsed:    0.5s remaining:    0.1s\n",
      "     |  [Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    0.5s finished\n",
      "     |  \n",
      "     |  Traceback example, note how the line of the error is indicated\n",
      "     |  as well as the values of the parameter passed to the function that\n",
      "     |  triggered the exception, even though the traceback happens in the\n",
      "     |  child process:\n",
      "     |  \n",
      "     |  >>> from heapq import nlargest\n",
      "     |  >>> from sklearn.externals.joblib import Parallel, delayed\n",
      "     |  >>> Parallel(n_jobs=2)(delayed(nlargest)(2, n) for n in (range(4), 'abcde', 3)) #doctest: +SKIP\n",
      "     |  #...\n",
      "     |  ---------------------------------------------------------------------------\n",
      "     |  Sub-process traceback:\n",
      "     |  ---------------------------------------------------------------------------\n",
      "     |  TypeError                                          Mon Nov 12 11:37:46 2012\n",
      "     |  PID: 12934                                    Python 2.7.3: /usr/bin/python\n",
      "     |  ...........................................................................\n",
      "     |  /usr/lib/python2.7/heapq.pyc in nlargest(n=2, iterable=3, key=None)\n",
      "     |      419         if n >= size:\n",
      "     |      420             return sorted(iterable, key=key, reverse=True)[:n]\n",
      "     |      421\n",
      "     |      422     # When key is none, use simpler decoration\n",
      "     |      423     if key is None:\n",
      "     |  --> 424         it = izip(iterable, count(0,-1))                    # decorate\n",
      "     |      425         result = _nlargest(n, it)\n",
      "     |      426         return map(itemgetter(0), result)                   # undecorate\n",
      "     |      427\n",
      "     |      428     # General case, slowest method\n",
      "     |   TypeError: izip argument #1 must support iteration\n",
      "     |  ___________________________________________________________________________\n",
      "     |  \n",
      "     |  \n",
      "     |  Using pre_dispatch in a producer/consumer situation, where the\n",
      "     |  data is generated on the fly. Note how the producer is first\n",
      "     |  called 3 times before the parallel loop is initiated, and then\n",
      "     |  called to generate new data on the fly. In this case the total\n",
      "     |  number of iterations cannot be reported in the progress messages:\n",
      "     |  \n",
      "     |  >>> from math import sqrt\n",
      "     |  >>> from sklearn.externals.joblib import Parallel, delayed\n",
      "     |  >>> def producer():\n",
      "     |  ...     for i in range(6):\n",
      "     |  ...         print('Produced %s' % i)\n",
      "     |  ...         yield i\n",
      "     |  >>> out = Parallel(n_jobs=2, verbose=100, pre_dispatch='1.5*n_jobs')(\n",
      "     |  ...                delayed(sqrt)(i) for i in producer()) #doctest: +SKIP\n",
      "     |  Produced 0\n",
      "     |  Produced 1\n",
      "     |  Produced 2\n",
      "     |  [Parallel(n_jobs=2)]: Done 1 jobs     | elapsed:  0.0s\n",
      "     |  Produced 3\n",
      "     |  [Parallel(n_jobs=2)]: Done 2 jobs     | elapsed:  0.0s\n",
      "     |  Produced 4\n",
      "     |  [Parallel(n_jobs=2)]: Done 3 jobs     | elapsed:  0.0s\n",
      "     |  Produced 5\n",
      "     |  [Parallel(n_jobs=2)]: Done 4 jobs     | elapsed:  0.0s\n",
      "     |  [Parallel(n_jobs=2)]: Done 5 out of 6 | elapsed:  0.0s remaining: 0.0s\n",
      "     |  [Parallel(n_jobs=2)]: Done 6 out of 6 | elapsed:  0.0s finished\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Parallel\n",
      "     |      sklearn.externals.joblib.logger.Logger\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, iterable)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, exc_type, exc_value, traceback)\n",
      "     |  \n",
      "     |  __init__(self, n_jobs=1, backend=None, verbose=0, timeout=None, pre_dispatch='2 * n_jobs', batch_size='auto', temp_folder=None, max_nbytes='1M', mmap_mode='r')\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      depth: int, optional\n",
      "     |          The depth of objects printed.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  dispatch_next(self)\n",
      "     |      Dispatch more data for parallel processing\n",
      "     |      \n",
      "     |      This method is meant to be called concurrently by the multiprocessing\n",
      "     |      callback. We rely on the thread-safety of dispatch_one_batch to protect\n",
      "     |      against concurrent consumption of the unprotected iterator.\n",
      "     |  \n",
      "     |  dispatch_one_batch(self, iterator)\n",
      "     |      Prefetch the tasks for the next batch and dispatch them.\n",
      "     |      \n",
      "     |      The effective size of the batch is computed here.\n",
      "     |      If there are no more jobs to dispatch, return False, else return True.\n",
      "     |      \n",
      "     |      The iterator consumption and dispatching is protected by the same\n",
      "     |      lock so calling this function should be thread safe.\n",
      "     |  \n",
      "     |  print_progress(self)\n",
      "     |      Display the process of the parallel execution only a fraction\n",
      "     |      of time, controlled by self.verbose.\n",
      "     |  \n",
      "     |  retrieve(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.externals.joblib.logger.Logger:\n",
      "     |  \n",
      "     |  debug(self, msg)\n",
      "     |  \n",
      "     |  format(self, obj, indent=0)\n",
      "     |      Return the formatted representation of the object.\n",
      "     |  \n",
      "     |  warn(self, msg)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.externals.joblib.logger.Logger:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    cpu_count()\n",
      "        Return the number of CPUs.\n",
      "    \n",
      "    delayed(function, check_pickle=True)\n",
      "        Decorator used to capture the arguments of a function.\n",
      "        \n",
      "        Pass `check_pickle=False` when:\n",
      "        \n",
      "        - performing a possibly repeated check is too costly and has been done\n",
      "          already once outside of the call to delayed.\n",
      "        \n",
      "        - when used in conjunction `Parallel(backend='threading')`.\n",
      "    \n",
      "    effective_n_jobs(n_jobs=-1)\n",
      "        Determine the number of jobs that can actually run in parallel\n",
      "        \n",
      "        n_jobs is the is the number of workers requested by the callers.\n",
      "        Passing n_jobs=-1 means requesting all available workers for instance\n",
      "        matching the number of CPU cores on the worker host(s).\n",
      "        \n",
      "        This method should return a guesstimate of the number of workers that can\n",
      "        actually perform work concurrently with the currently enabled default\n",
      "        backend. The primary use case is to make it possible for the caller to know\n",
      "        in how many chunks to slice the work.\n",
      "        \n",
      "        In general working on larger data chunks is more efficient (less\n",
      "        scheduling overhead and better use of CPU cache prefetching heuristics)\n",
      "        as long as all the workers have enough work to do.\n",
      "        \n",
      "        Warning: this function is experimental and subject to change in a future\n",
      "        version of joblib.\n",
      "        \n",
      "        .. versionadded:: 0.10\n",
      "    \n",
      "    get_active_backend()\n",
      "        Return the active default backend\n",
      "    \n",
      "    parallel_backend(backend, n_jobs=-1, **backend_params)\n",
      "        Change the default backend used by Parallel inside a with block.\n",
      "        \n",
      "        If ``backend`` is a string it must match a previously registered\n",
      "        implementation using the ``register_parallel_backend`` function.\n",
      "        \n",
      "        Alternatively backend can be passed directly as an instance.\n",
      "        \n",
      "        By default all available workers will be used (``n_jobs=-1``) unless the\n",
      "        caller passes an explicit value for the ``n_jobs`` parameter.\n",
      "        \n",
      "        This is an alternative to passing a ``backend='backend_name'`` argument to\n",
      "        the ``Parallel`` class constructor. It is particularly useful when calling\n",
      "        into library code that uses joblib internally but does not expose the\n",
      "        backend argument in its own API.\n",
      "        \n",
      "        >>> from operator import neg\n",
      "        >>> with parallel_backend('threading'):\n",
      "        ...     print(Parallel()(delayed(neg)(i + 1) for i in range(5)))\n",
      "        ...\n",
      "        [-1, -2, -3, -4, -5]\n",
      "        \n",
      "        Warning: this function is experimental and subject to change in a future\n",
      "        version of joblib.\n",
      "        \n",
      "        .. versionadded:: 0.10\n",
      "    \n",
      "    register_parallel_backend(name, factory, make_default=False)\n",
      "        Register a new Parallel backend factory.\n",
      "        \n",
      "        The new backend can then be selected by passing its name as the backend\n",
      "        argument to the Parallel class. Moreover, the default backend can be\n",
      "        overwritten globally by setting make_default=True.\n",
      "        \n",
      "        The factory can be any callable that takes no argument and return an\n",
      "        instance of ``ParallelBackendBase``.\n",
      "        \n",
      "        Warning: this function is experimental and subject to change in a future\n",
      "        version of joblib.\n",
      "        \n",
      "        .. versionadded:: 0.10\n",
      "    \n",
      "    sqrt(...)\n",
      "        sqrt(x)\n",
      "        \n",
      "        Return the square root of x.\n",
      "\n",
      "DATA\n",
      "    BACKENDS = {'multiprocessing': <class 'sklearn.externals.joblib._paral...\n",
      "    DEFAULT_BACKEND = 'multiprocessing'\n",
      "    DEFAULT_MP_CONTEXT = <multiprocessing.context.SpawnContext object>\n",
      "    DEFAULT_N_JOBS = 1\n",
      "    division = _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192...\n",
      "    method = None\n",
      "\n",
      "FILE\n",
      "    c:\\users\\purne\\miniconda3\\envs\\py36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\n",
      "\n",
      "\n",
      "building tree 1 of 5building tree 2 of 5\n",
      "\n",
      "building tree 3 of 5\n",
      "building tree 4 of 5\n",
      "building tree 5 of 5\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed: 27.3min\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed: 28.0min remaining: 42.0min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed: 29.2min remaining: 19.5min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 30.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed: 30.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('rand_forest_feats', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('numeric_feats', TypeSelector(dtype=<class 'numpy.number'>)), ('one_hot_encoded_feats', Pipeline(memory=None,\n",
       "     steps=[('extract_columns', ColumnSelector(column_list=['shop_id', 'month'])), ('one_hot_encoding', OneHotEn...stimators=5, n_jobs=-1,\n",
       "           oob_score=False, random_state=0, verbose=100, warm_start=False))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "help(joblib.parallel)\n",
    "\n",
    "# fit and predict\n",
    "rand_forest_pipeline.fit(x_train, y_train)   \n",
    "# print(len(one_hot_encode.fit_transform(x_train, y_train).toarray()[0]))\n",
    "\n",
    "# print( len(x_train.month.unique()) ,  len(x_train.shop_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   3 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "rf_predictions = np.round(rand_forest_pipeline.predict(x_vald))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.593162599661754\n",
      "Mean Squared Error: 42.0776757670935\n",
      "Root Mean Squared Error: 6.4867307456910455\n",
      "\n",
      "Avg. count for each shop-item pair: 2.034\n",
      "MAPE is 78.32 percent of avg_scan_count\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(vald.item_cnt_month, rf_predictions))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(vald.item_cnt_month, rf_predictions))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(vald.item_cnt_month, rf_predictions)))\n",
    "print(\"\\nAvg. count for each shop-item pair: {}\".format(np.round(vald.item_cnt_month.mean(), 3)))\n",
    "\n",
    "pct = metrics.mean_absolute_error(vald.item_cnt_month, rf_predictions) / vald.item_cnt_month.mean() * 100\n",
    "print(\"MAPE is {} percent of avg_scan_count\".format(np.round(pct,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation (for hyperparams tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kfold = KFold(n_splits=10, random_state=seed)\n",
    "custom_cv = CustomCVSplit(n_splits=5)\n",
    "results = cross_val_score(pipeline, x_train, y_train, cv=custom_cv, scoring='r2', groups=groups)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
